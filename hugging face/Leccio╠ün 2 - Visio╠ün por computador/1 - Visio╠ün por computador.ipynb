{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f7568a2",
   "metadata": {},
   "source": [
    "# 1 - Visión por computador\n",
    "\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/Hack-io-AI/ai_images/main/computer_vision.webp\" style=\"width:400px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e32c9f",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Tabla de Contenidos<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#1---Definición\" data-toc-modified-id=\"1---Definición-1\">1 - Definición</a></span></li><li><span><a href=\"#2---¿Qué-son-los-Diffusers?\" data-toc-modified-id=\"2---¿Qué-son-los-Diffusers?-2\">2 - ¿Qué son los Diffusers?</a></span></li><li><span><a href=\"#3---Limitaciones\" data-toc-modified-id=\"3---Limitaciones-3\">3 - Limitaciones</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760ea95c",
   "metadata": {},
   "source": [
    "## 1 - Definición"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69a1180",
   "metadata": {},
   "source": [
    "La visión por computador, Computer Vision en inglés, es un campo de la inteligencia artificial que se enfoca en enseñar a las computadoras a interpretar y comprender el contenido del mundo visual, como imágenes y videos. A través de algoritmos y técnicas avanzadas, las computadoras pueden procesar, analizar y tomar decisiones basadas en datos visuales. \n",
    "\n",
    "\n",
    "\n",
    "**Componentes y técnicas de la visión por computador**:\n",
    "\n",
    "\n",
    "1. **Captura de imágenes**: Utiliza dispositivos como cámaras, sensores y escáneres para obtener imágenes digitales del entorno.\n",
    "\n",
    "\n",
    "2. **Preprocesamiento de imágenes**: Involucra la mejora de la calidad de las imágenes y la eliminación de ruido. Técnicas comunes incluyen la filtración, la normalización de iluminación y la corrección de color.\n",
    "\n",
    "\n",
    "3. **Segmentación de imágenes**: Divide una imagen en partes o regiones para aislar objetos de interés. Esto puede incluir técnicas como la detección de bordes y la agrupación de píxeles similares.\n",
    "\n",
    "\n",
    "4. **Detección y reconocimiento de objetos**: Involucra identificar y clasificar objetos dentro de una imagen. Técnicas como la detección de características, por ejemplo, esquinas o bordes, con el uso de modelos preentrenados para reconocer objetos específicos.\n",
    "\n",
    "\n",
    "5. **Seguimiento de objetos**: Se refiere a seguir el movimiento de objetos a través de una serie de imágenes o videos. Esto es útil en aplicaciones como la vigilancia y la conducción autónoma.\n",
    "\n",
    "\n",
    "6. **Reconocimiento de patrones**: Incluye el reconocimiento de formas, texturas y otros patrones en las imágenes. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92768c9b",
   "metadata": {},
   "source": [
    "**Aplicaciones de la visión por computador**:\n",
    "\n",
    "\n",
    "1. **Reconocimiento facial**: Utilizado en seguridad, autenticación y redes sociales para identificar y verificar personas.\n",
    "\n",
    "\n",
    "2. **Automóviles autónomos**: Los sistemas de visión por computador ayudan a los vehículos a detectar señales de tráfico, peatones y otros vehículos para una conducción segura.\n",
    "\n",
    "\n",
    "3. **Diagnóstico médico**: Análisis de imágenes médicas como radiografías, resonancias magnéticas y tomografías para detectar enfermedades y condiciones médicas.\n",
    "\n",
    "\n",
    "4. **Control de calidad en manufactura**: Inspección automatizada de productos para detectar defectos y garantizar estándares de calidad.\n",
    "\n",
    "\n",
    "5. **Realidad aumentada y virtual**: Integración de objetos virtuales en el mundo real o creación de entornos virtuales interactivos.\n",
    "\n",
    "\n",
    "6. **Seguridad y vigilancia**: Monitoreo automático de áreas y detección de actividades sospechosas o anómalas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decc1e56",
   "metadata": {},
   "source": [
    "**Desafíos en la visión por computador**:\n",
    "\n",
    "\n",
    "1. **Variabilidad del entorno**: Las condiciones de iluminación, las posiciones de los objetos y las obstrucciones pueden complicar el análisis de las imágenes.\n",
    "\n",
    "\n",
    "2. **Escalabilidad**: Procesar grandes volúmenes de datos visuales en tiempo real requiere una considerable capacidad computacional.\n",
    "\n",
    "\n",
    "3. **Precisión**: La capacidad de distinguir correctamente entre objetos similares y evitar falsos positivos o negativos.\n",
    "\n",
    "\n",
    "4. **Interpretación del contexto**: Comprender el contexto en el que se encuentran los objetos y las acciones dentro de una imagen o video puede ser complejo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70ecbab",
   "metadata": {},
   "source": [
    "## 2 - ¿Qué son los Diffusers?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0a9f6c",
   "metadata": {},
   "source": [
    "Los Diffusers, o técnicas de difusión, son una clase de métodos utilizados en el aprendizaje automático, específicamente en los modelos generativos. Estos métodos se basan en procesos de difusión que transforman datos a través de una serie de pasos ruidosos y luego aprenden a revertir ese proceso para generar nuevos datos realistas. \n",
    "\n",
    "\n",
    "\n",
    "**Principios básicos de las técnicas de difusión**\n",
    "\n",
    "\n",
    "+ Proceso de difusión directa: Este proceso implica añadir gradualmente ruido a los datos originales a través de una serie de pasos hasta que los datos se convierten en ruido puro. Este paso es conocido como \"difusión directa\".\n",
    "\n",
    "\n",
    "+ Proceso de difusión inversa: En este proceso, el modelo aprende a eliminar el ruido paso a paso para recuperar los datos originales. A este paso se le llama \"difusión inversa\".\n",
    "\n",
    "\n",
    "\n",
    "**Componentes Clave de las Técnicas de Difusión**\n",
    "\n",
    "\n",
    "+ Ruido gaussiano: Se utiliza ruido gaussiano, ruido blanco, para perturbar los datos originales durante el proceso de difusión directa.\n",
    "\n",
    "\n",
    "+ Pérdida de información y reconstrucción: La idea es que el modelo aprenda a reconstruir la información perdida al revertir el proceso de adición de ruido.\n",
    "\n",
    "\n",
    "+ Modelado de la distribución de datos: El objetivo es modelar la distribución de los datos originales para poder generar nuevos datos que sigan la misma distribución.\n",
    "\n",
    "\n",
    "\n",
    "**Tipos de Modelos de Difusión**\n",
    "\n",
    "\n",
    "+ Modelos de difusión Denoising Score Matching (DSM): Estos modelos aprenden a estimar gradientes, o scores, que apuntan hacia áreas de alta densidad de datos, lo que les permite eliminar el ruido de manera efectiva.\n",
    "\n",
    "\n",
    "+ Modelos de difusión variacional: Basados en los principios de la inferencia variacional, una técnica de aproximación utilizada en la estadística bayesiana para estimar distribuciones complejas, estos modelos aprenden a aproximar la distribución de los datos originales y generar nuevos datos a partir de esa distribución.\n",
    "\n",
    "\n",
    "\n",
    "**Ventajas de las Técnicas de Difusión**\n",
    "\n",
    "\n",
    "+ Generación de Alta Calidad: Capaces de generar datos de alta calidad y detalles finos.\n",
    "\n",
    "\n",
    "+ Estabilidad del Proceso: Los procesos de difusión tienden a ser más estables y menos propensos a colapsar durante el entrenamiento en comparación con otras técnicas generativas como las GANs (Generative Adversarial Networks).\n",
    "\n",
    "\n",
    "+ Flexibilidad: Pueden ser aplicados a una amplia variedad de tipos de datos, incluyendo imágenes, audio y texto.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc97d07",
   "metadata": {},
   "source": [
    "En Hugging Face, además de la biblioteca `transformers`, usaremos también la biblioteca `diffusers` que proporciona herramientas para implementar, entrenar y desplegar modelos de difusión.\n",
    "\n",
    "\n",
    "**Componentes de la Biblioteca Diffusers**\n",
    "\n",
    "\n",
    "1. Modelos preentrenados: La biblioteca incluye una variedad de modelos de difusión preentrenados que se pueden usar para diferentes tareas de generación de datos, como la generación de imágenes, audio y más.\n",
    "\n",
    "\n",
    "2. APIs fáciles de usar: Ofrece interfaces de programación sencillas para cargar modelos, ajustar hiperparámetros y realizar inferencias.\n",
    "\n",
    "\n",
    "3. Compatibilidad con transformers: La biblioteca está diseñada para integrarse fácilmente con la biblioteca transformers de Hugging Face, permitiendo la combinación de modelos de lenguaje con modelos de difusión.\n",
    "\n",
    "\n",
    "4. Documentación y ejemplos: La biblioteca incluye documentación detallada y ejemplos de uso para ayudar a los desarrolladores a comenzar rápidamente.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d251d76c",
   "metadata": {},
   "source": [
    "## 3 - Limitaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4c3793",
   "metadata": {},
   "source": [
    "Las técnicas de difusión, aunque poderosas y efectivas en muchos aspectos, también tienen sus limitaciones. \n",
    "\n",
    "\n",
    "+ **Complejidad computacional y alta demanda de recursos**:Las técnicas de difusión requieren una cantidad significativa de recursos computacionales, tanto en términos de memoria como de potencia de procesamiento. Los modelos deben realizar una gran cantidad de pasos de difusión directa e inversa, lo que puede ser costoso y lento.\n",
    "\n",
    "\n",
    "+ **Largo tiempo de entrenamiento**: El entrenamiento de modelos de difusión puede ser extremadamente lento debido al número de iteraciones necesarias para converger. Esto puede ser un impedimento significativo para aplicaciones que requieren resultados rápidos o tiempo real.\n",
    "\n",
    "\n",
    "+ **Largo tiempo de generación**: Generar nuevas muestras utilizando técnicas de difusión también puede ser un proceso lento, ya que involucra aplicar múltiples pasos de eliminación de ruido para cada muestra generada.\n",
    "\n",
    "\n",
    "+ **Complejidad del modelo**: Diseñar y ajustar correctamente un modelo de difusión puede ser complejo. Requiere un profundo entendimiento de la dinámica de difusión y cómo establecer los parámetros de ruido y las funciones de pérdida adecuadas.\n",
    "\n",
    "\n",
    "+ **Dependencia de datos de alta calidad**: La calidad de las muestras generadas por modelos de difusión depende en gran medida de la calidad y cantidad de los datos de entrenamiento. Si los datos de entrenamiento son ruidosos o insuficientes, el modelo puede no generalizar bien.\n",
    "\n",
    "\n",
    "+ **Dificultad para interpretar**: Los modelos de difusión, como muchos modelos de aprendizaje profundo, pueden ser difíciles de interpretar y entender. Es difícil saber exactamente cómo y por qué el modelo toma ciertas decisiones durante el proceso de generación.\n",
    "\n",
    "\n",
    "+ **Control sobre el proceso de generación**: Aunque los modelos de difusión pueden generar datos de alta calidad, puede ser difícil controlar aspectos específicos de las muestras generadas. La naturaleza estocástica del proceso de difusión puede hacer que sea desafiante producir muestras con características específicas predefinidas.\n",
    "\n",
    "\n",
    "+ **Sensibilidad al ruido**: Si el modelo no está bien entrenado, puede ser sensible al ruido y producir resultados de baja calidad. El proceso de eliminación de ruido debe estar muy bien ajustado para asegurar que las muestras generadas sean coherentes y de alta calidad.\n",
    "\n",
    "\n",
    "+ **Generalización a nuevos datos**: Los modelos de difusión pueden tener dificultades para generalizar a distribuciones de datos diferentes a las de su entrenamiento. Esto puede limitar su aplicabilidad a nuevos dominios o tipos de datos sin un retrenamiento significativo.\n",
    "\n",
    "\n",
    "+ **Comparación con GANs**: Aunque las técnicas de difusión pueden ser más estables y producir resultados de alta calidad, suelen ser más lentas que las Generative Adversarial Networks (GANs) en términos de tiempo de generación. Las GANs pueden generar muestras muy rápidamente una vez entrenadas.\n",
    "\n",
    "\n",
    "+ **Curva de aprendizaje**: La implementación y el uso efectivo de técnicas de difusión pueden tener una curva de aprendizaje mayor. Requiere conocimiento en profundidad de los métodos de inferencia variacional, optimización y procesamiento de señales."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ia",
   "language": "python",
   "name": "ia"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Tabla de Contenidos",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "599px",
    "left": "86px",
    "top": "0px",
    "width": "204.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
