{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5248ef85",
   "metadata": {},
   "source": [
    "# 8 - Clafisicación de audio\n",
    "\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/Hack-io-AI/ai_images/main/audio_classifier.webp\" style=\"width:400px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca53b15",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Tabla de Contenidos<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#1---Modelos-de-clasificación-de-audio\" data-toc-modified-id=\"1---Modelos-de-clasificación-de-audio-1\">1 - Modelos de clasificación de audio</a></span></li><li><span><a href=\"#2---Modelo-clasificación-de-género-musical\" data-toc-modified-id=\"2---Modelo-clasificación-de-género-musical-2\">2 - Modelo clasificación de género musical</a></span></li><li><span><a href=\"#3---Modelo-de-análisis-de-sentimimento\" data-toc-modified-id=\"3---Modelo-de-análisis-de-sentimimento-3\">3 - Modelo de análisis de sentimimento</a></span></li><li><span><a href=\"#4---Modelo-reconocimiento-de-acentos\" data-toc-modified-id=\"4---Modelo-reconocimiento-de-acentos-4\">4 - Modelo reconocimiento de acentos</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3dc3c13",
   "metadata": {},
   "source": [
    "## 1 - Modelos de clasificación de audio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198155e5",
   "metadata": {},
   "source": [
    "Los modelos de clasificación de audio son sistemas de inteligencia artificial diseñados para identificar y categorizar distintos tipos de sonidos en grabaciones de audio. Estos modelos se utilizan en una amplia gama de aplicaciones, desde la detección de eventos acústicos hasta el reconocimiento de música y voz. \n",
    "\n",
    "\n",
    "**Componentes principales**\n",
    "\n",
    "\n",
    "1. **Extracción de características**:\n",
    "\n",
    "    + MFCC (Mel-Frequency Cepstral Coefficients): Una de las técnicas más comunes para la extracción de características en el procesamiento de audio. MFCCs capturan las propiedades espectrales de los sonidos, imitando la forma en que el oído humano percibe el sonido.\n",
    "    + Espectrogramas: Representaciones visuales de la energía de la señal de audio a través del tiempo en diferentes frecuencias. Los espectrogramas pueden ser usados directamente como entradas para modelos de aprendizaje profundo.\n",
    "    + Chroma Features: Representaciones que capturan la información tonal de una señal de audio, útil en la clasificación de música.\n",
    "\n",
    "\n",
    "2. **Modelos de aprendizaje automático**:\n",
    "\n",
    "    + Redes neuronales convolucionales (CNNs): Utilizadas para analizar los espectrogramas de audio, las CNNs son efectivas en la captura de patrones espaciales y temporales en los datos de audio.\n",
    "    + Redes neuronales recurrentes (RNNs): Especialmente las LSTM (Long Short-Term Memory), son útiles para manejar secuencias de datos temporales y capturar dependencias a largo plazo en el audio.\n",
    "    + Transformers: Más recientes en el campo del procesamiento de audio, los Transformers pueden capturar relaciones a largo plazo en las secuencias de audio sin necesidad de procesar los datos de forma secuencial.\n",
    "\n",
    "\n",
    "3. **Preprocesamiento y normalización**:\n",
    "\n",
    "    + Normalización del Audio: Ajustar la amplitud del audio para asegurar que todas las muestras tengan niveles de volumen similares.\n",
    "    + Alineación temporal: Asegurar que las muestras de audio estén alineadas temporalmente, especialmente importante en el reconocimiento de voz y en aplicaciones que requieren sincronización precisa.\n",
    "\n",
    "<br>\n",
    "\n",
    "**Tipos de modelos de clasificación de audio**\n",
    "\n",
    "\n",
    "1. **Reconocimiento automático del habla (ASR)**: Ejemplos incluyen DeepSpeech y los modelos de Google Speech-to-Text. Aplicaciones como transcripción de voz a texto, asistentes virtuales como Alexa y Google Assistant.\n",
    "\n",
    "\n",
    "2. **Clasificación de géneros musicales**: CNNs entrenadas en espectrogramas de música. Aplicaciones como servicios de streaming de música que organizan y recomiendan canciones por género.\n",
    "\n",
    "\n",
    "3. **Detección de eventos acústicos**: Redes profundas y métodos basados en CNN. Aplicaciones como sistemas de vigilancia, monitoreo de biodiversidad y detección de fallos en maquinaria.\n",
    "\n",
    "\n",
    "4. **Identificación de oradores**: Modelos basados en embeddings de voz como los generados por x-vectors. Aplicaciones como seguridad, autenticación biométrica y análisis de conversaciones.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb02d62",
   "metadata": {},
   "source": [
    "## 2 - Modelo clasificación de género musical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56782647",
   "metadata": {},
   "source": [
    "Este [modelo](Yash03813/pingpong-music_genres_classification-finetuned-finetuned-gtzan), entrenado con el dataset [GTZAN](https://huggingface.co/datasets/marsyas/gtzan) y que tiene un peso de unos 400Mb, es capaz de reconocer el género musical de un audio. Usaremos el modelo con el archivo que generamos anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44acc294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# para quitar warnings \n",
    "\n",
    "from transformers import logging\n",
    "logging.set_verbosity_error()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be051dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importamos desde la librería transformers el pipeline\n",
    "\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "040ba6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definimos la tarea y el modelo\n",
    "\n",
    "tarea = 'audio-classification'  \n",
    "\n",
    "modelo = 'Yash03813/pingpong-music_genres_classification-finetuned-finetuned-gtzan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c78077d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iniciamos el modelo, los modelos se descargan en local, en este caso son unos 400Mb\n",
    "\n",
    "pipe = pipeline(task=tarea, model=modelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "121c5f10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.9464476704597473, 'label': 'metal'},\n",
       " {'score': 0.02261282317340374, 'label': 'rock'},\n",
       " {'score': 0.008514848537743092, 'label': 'jazz'},\n",
       " {'score': 0.00737546943128109, 'label': 'hiphop'},\n",
       " {'score': 0.004858397878706455, 'label': 'classical'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe('../../../files/jazz_sample.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0bd142",
   "metadata": {},
   "source": [
    "## 3 - Modelo de análisis de sentimimento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33dbd690",
   "metadata": {},
   "source": [
    "Podemos usar modelos de audio a audio para realizar un análisis de sentimiento sobre una pieza de audio. Este [modelo](ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition) realiza dicho análisis sobre muestras de voz, tiene un peso de aproximadamaente 1.3Gb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6fd5c0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definimos la tarea y el modelo\n",
    "\n",
    "tarea = 'audio-classification'  \n",
    "\n",
    "modelo = 'ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "051c314c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iniciamos el modelo, los modelos se descargan en local, en este caso son unos 1.3Gb\n",
    "\n",
    "pipe = pipeline(task=tarea, model=modelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "451dd6e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.13121157884597778, 'label': 'sad'},\n",
       " {'score': 0.12992899119853973, 'label': 'disgust'},\n",
       " {'score': 0.12929537892341614, 'label': 'surprised'},\n",
       " {'score': 0.12623372673988342, 'label': 'neutral'},\n",
       " {'score': 0.1251295506954193, 'label': 'calm'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe('audio_cache/test_mixture_3spks.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb48cee",
   "metadata": {},
   "source": [
    "## 4 - Modelo reconocimiento de acentos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2544df8a",
   "metadata": {},
   "source": [
    "También podemos reconocer los distintos acentos de un idioma con este [modelo](dima806/english_accents_classification). Pesa unos 400Mb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a452572e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definimos la tarea y el modelo\n",
    "\n",
    "tarea = 'audio-classification'  \n",
    "\n",
    "modelo = 'dima806/english_accents_classification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c7f1526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iniciamos el modelo, los modelos se descargan en local, en este caso son unos 400Mb\n",
    "\n",
    "pipe = pipeline(task=tarea, model=modelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bdfe76f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.6732790470123291, 'label': 'indian'},\n",
       " {'score': 0.17696593701839447, 'label': 'us'},\n",
       " {'score': 0.09264418482780457, 'label': 'england'},\n",
       " {'score': 0.028835738077759743, 'label': 'canada'},\n",
       " {'score': 0.028275076299905777, 'label': 'australia'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe('audio_cache/test_mixture_3spks.wav')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ia",
   "language": "python",
   "name": "ia"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Tabla de Contenidos",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "684.436px",
    "left": "79px",
    "top": "110.113px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
