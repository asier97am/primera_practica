{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f358d30b",
   "metadata": {},
   "source": [
    "# 1 - Audio\n",
    "\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/Hack-io-AI/ai_images/main/computer_audio.webp\" style=\"width:400px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635a77c4",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Tabla de Contenidos<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#1---Definición\" data-toc-modified-id=\"1---Definición-1\">1 - Definición</a></span></li><li><span><a href=\"#2---Modelos-de-Audición-por-Computador\" data-toc-modified-id=\"2---Modelos-de-Audición-por-Computador-2\">2 - Modelos de Audición por Computador</a></span></li><li><span><a href=\"#3---Usos-de-la-Audición-por-Computador\" data-toc-modified-id=\"3---Usos-de-la-Audición-por-Computador-3\">3 - Usos de la Audición por Computador</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be346313",
   "metadata": {},
   "source": [
    "## 1 - Definición"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23230e9a",
   "metadata": {},
   "source": [
    "La audición por computador, también conocida como audición computacional, es un campo de la inteligencia artificial y el procesamiento de señales que se enfoca en la percepción y comprensión de sonidos y señales de audio por parte de sistemas informáticos. Este campo abarca una variedad de técnicas y modelos que permiten a las máquinas analizar, interpretar y generar sonidos de manera similar a cómo lo hacen los seres humanos. Esto puede incluir tareas como la detección de eventos sonoros, el reconocimiento de voz, la identificación de música, la separación de fuentes sonoras y la síntesis de audio. El objetivo es desarrollar sistemas que puedan interactuar de manera efectiva con el entorno auditivo y proporcionar información útil basada en el análisis del sonido.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641ea904",
   "metadata": {},
   "source": [
    "## 2 - Modelos de Audición por Computador"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d85c2e0",
   "metadata": {},
   "source": [
    "1. **Reconocimiento automático del habla** (ASR - Automatic Speech Recognition):\n",
    "\n",
    "    + Modelos acústicos: Utilizan redes neuronales profundas (DNN), modelos ocultos de Markov (HMM) y redes neuronales convolucionales (CNN) para mapear las características del audio a fonemas.\n",
    "    + Modelos de lenguaje: Utilizan técnicas de NLP como modelos [n-gram](https://es.wikipedia.org/wiki/N-grama) y modelos de transformer para predecir secuencias de palabras.\n",
    "\n",
    "\n",
    "2. **Reconocimiento de música y audio** (MIR - Music Information Retrieval):\n",
    "\n",
    "    + Modelos de clasificación de género musical: Utilizan redes neuronales recurrentes (RNN) y CNNs para clasificar música en diferentes géneros.\n",
    "    + Detección de tempo y ritmo: Algoritmos que analizan la periodicidad de las señales de audio para detectar el tempo y el ritmo de una pieza musical.\n",
    "    + Reconocimiento de melodía y armonía: Modelos que extraen y analizan la melodía y la estructura armónica de la música.\n",
    "\n",
    "\n",
    "3. **Separación de fuentes sonoras**:\n",
    "\n",
    "    + Redes neuronales profundas: Modelos como U-Net y Wave-U-Net que se utilizan para separar diferentes fuentes sonoras en una grabación de audio.\n",
    "    + Algoritmos de factorización de matrices: Técnicas como la factorización de matrices no negativas (NMF) para descomponer una señal de audio en componentes básicos.\n",
    "\n",
    "\n",
    "4. **Detección de eventos sonoros** (SED - Sound Event Detection):\n",
    "\n",
    "    + Modelos basados en CNNs y RNNs: Utilizados para detectar y clasificar eventos sonoros específicos en un entorno, como pasos o puertas cerrándose.\n",
    "    + Modelos híbridos: Combinan CNNs y RNNs para capturar características espaciales y temporales del audio.\n",
    "\n",
    "\n",
    "4. **Síntesis y generación de audio**:\n",
    "\n",
    "    + Modelos de síntesis de texto a voz (TTS - Text to Speech): Modelos como WaveNet y Tacotron que convierten texto escrito en habla sintética.\n",
    "    + Generación de música: Modelos basados en GANs, RNNs o Diffusers para la creación de composiciones musicales originales.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60ddd11",
   "metadata": {},
   "source": [
    "## 3 - Usos de la Audición por Computador"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf78b0b",
   "metadata": {},
   "source": [
    "\n",
    "1. **Asistentes virtuales** Integración de ASR y TTS para crear asistentes de voz como Siri, Alexa y Google Assistant que pueden entender y responder a comandos de voz.\n",
    "\n",
    "\n",
    "2. **Sistemas de seguridad y vigilancia**: Detección de eventos sonoros críticos como alarmas, vidrios rotos o gritos para alertar sobre posibles situaciones de emergencia.\n",
    "\n",
    "\n",
    "3. **Aplicaciones médicas** Análisis de sonidos cardíacos y respiratorios para el diagnóstico de enfermedades. Sistemas de asistencia para personas con discapacidades auditivas mediante la traducción de sonido a texto.\n",
    "\n",
    "\n",
    "4. **Entretenimiento y medios**: Reconocimiento y recomendación de música en plataformas como Spotify y Apple Music. Sincronización de efectos de sonido y diálogos en la producción cinematográfica.\n",
    "\n",
    "\n",
    "5. **Automatización del hogar**: Control de dispositivos inteligentes mediante comandos de voz. Detección de sonidos anormales en el hogar, como fugas de agua o fallos en electrodomésticos.\n",
    "\n",
    "\n",
    "6. **Vehículos autónomos**: Detección de señales sonoras del entorno, como sirenas de emergencia, para tomar decisiones de conducción adecuadas.\n",
    "\n",
    "\n",
    "7. **Investigación y desarrollo**: Análisis de grandes volúmenes de datos de audio para estudios en lingüística, acústica y comportamiento humano.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ia",
   "language": "python",
   "name": "ia"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Tabla de Contenidos",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "598px",
    "left": "39px",
    "top": "0px",
    "width": "302.398px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
