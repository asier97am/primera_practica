{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "269d02d6",
   "metadata": {},
   "source": [
    "# 14 - Fine Tuning / Datasets\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/Hack-io-AI/ai_images/main/tuning.webp\" style=\"width:400px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e4f2f8",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Tabla de Contenidos<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#1---¿Qué-es-el-fine-tuning?\" data-toc-modified-id=\"1---¿Qué-es-el-fine-tuning?-1\">1 - ¿Qué es el fine tuning?</a></span></li><li><span><a href=\"#2---Datasets\" data-toc-modified-id=\"2---Datasets-2\">2 - Datasets</a></span></li><li><span><a href=\"#3---Ejemplos-de-datasets\" data-toc-modified-id=\"3---Ejemplos-de-datasets-3\">3 - Ejemplos de datasets</a></span><ul class=\"toc-item\"><li><span><a href=\"#3.1---GLUE-(General-Language-Understanding-Evaluation)\" data-toc-modified-id=\"3.1---GLUE-(General-Language-Understanding-Evaluation)-3.1\">3.1 - GLUE (General Language Understanding Evaluation)</a></span></li><li><span><a href=\"#3.2---Análisis-de-sentimiento-en-Twitter\" data-toc-modified-id=\"3.2---Análisis-de-sentimiento-en-Twitter-3.2\">3.2 - Análisis de sentimiento en Twitter</a></span></li></ul></li><li><span><a href=\"#4---Fine-Tuning-GLUE\" data-toc-modified-id=\"4---Fine-Tuning-GLUE-4\">4 - Fine Tuning GLUE</a></span><ul class=\"toc-item\"><li><span><a href=\"#4.1---Tokenizador-y-Modelo-BERT\" data-toc-modified-id=\"4.1---Tokenizador-y-Modelo-BERT-4.1\">4.1 - Tokenizador y Modelo BERT</a></span></li><li><span><a href=\"#4.2---Tokenizando-el-dataset\" data-toc-modified-id=\"4.2---Tokenizando-el-dataset-4.2\">4.2 - Tokenizando el dataset</a></span></li><li><span><a href=\"#4.3---Data-Collator\" data-toc-modified-id=\"4.3---Data-Collator-4.3\">4.3 - Data Collator</a></span></li><li><span><a href=\"#4.4---Trainer\" data-toc-modified-id=\"4.4---Trainer-4.4\">4.4 - Trainer</a></span></li><li><span><a href=\"#4.5---Predicción-y-evaluación\" data-toc-modified-id=\"4.5---Predicción-y-evaluación-4.5\">4.5 - Predicción y evaluación</a></span></li><li><span><a href=\"#4.6---Guardado-del-modelo\" data-toc-modified-id=\"4.6---Guardado-del-modelo-4.6\">4.6 - Guardado del modelo</a></span></li></ul></li><li><span><a href=\"#5---Fine-Tuning-Análisis-de-Sentimiento\" data-toc-modified-id=\"5---Fine-Tuning-Análisis-de-Sentimiento-5\">5 - Fine Tuning Análisis de Sentimiento</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0031bc3c",
   "metadata": {},
   "source": [
    "## 1 - ¿Qué es el fine tuning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebfd740",
   "metadata": {},
   "source": [
    "El \"fine tuning\" o ajuste fino en el contexto de modelos de aprendizaje automático, especialmente en modelos de NLP como BERT o GPT, es una técnica de entrenamiento donde un modelo previamente entrenado en un gran conjunto de datos, preentrenamiento, es posteriormente ajustado con un conjunto de datos más pequeño y específico para una tarea concreta. Este proceso adapta el modelo a las particularidades de una aplicación específica, mejorando su rendimiento en esa tarea.\n",
    "\n",
    "\n",
    "**Cómo Funciona el Fine Tuning**\n",
    "\n",
    "\n",
    "1. Preentrenamiento: Inicialmente, el modelo se entrena en una gran cantidad de datos generales para aprender una amplia representación del lenguaje. Este entrenamiento generalista permite que el modelo adquiera una comprensión básica de la estructura y semántica del lenguaje.\n",
    "\n",
    "2. Ajuste Fino: Luego, el modelo se entrena, se realiza el ajuste fino, en un conjunto de datos más pequeño pero específico para la tarea. Por ejemplo, si el objetivo es clasificar emails en categorías, el modelo se ajusta fino con un conjunto de emails etiquetados.\n",
    "\n",
    "\n",
    "**Ventajas del Fine Tuning**\n",
    "\n",
    "\n",
    "+ Especialización: Permite que el modelo se especialice en las características específicas de los datos o las tareas particulares, lo que generalmente lleva a un mejor rendimiento en comparación con el uso directo de modelos preentrenados.\n",
    "\n",
    "+ Eficiencia: El ajuste fino suele requerir menos recursos computacionales y tiempo en comparación con el entrenamiento de un modelo desde cero, ya que el modelo ya ha aprendido patrones de lenguaje generales durante el preentrenamiento.\n",
    "\n",
    "+ Flexibilidad: Los modelos pueden ser rápidamente adaptados a nuevas tareas con solo ajustarlos sobre nuevos conjuntos de datos.\n",
    "\n",
    "\n",
    "**Consideraciones al Realizar Fine Tuning**\n",
    "\n",
    "\n",
    "+ Overfitting: Debido a que el ajuste fino se realiza a menudo con conjuntos de datos más pequeños, hay un riesgo de overfitting, donde el modelo se ajusta demasiado a los datos de entrenamiento y pierde la capacidad de generalizar a datos no vistos.\n",
    "\n",
    "+ Selección de Hiperparámetros: Es crucial seleccionar adecuadamente los hiperparámetros como la tasa de aprendizaje o el número de épocas, para asegurar que el modelo se ajuste de manera efectiva sin sobreajustarse.\n",
    "\n",
    "+ Calidad de los Datos de Entrenamiento: La calidad y la relevancia del conjunto de datos utilizado para el ajuste fino tienen un impacto significativo en el rendimiento del modelo ajustado.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47df954",
   "metadata": {},
   "source": [
    "## 2 - Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab7cfaa",
   "metadata": {},
   "source": [
    "Acabamos de decir que la calidad y la relevancia del conjunto de datos utilizado para el ajuste fino tienen un impacto significativo en el rendimiento del modelo ajustado. Hugging Face también ofrece una amplia colección de conjuntos de datos, datasets, que son fundamentales para entrenar, ajustar fino y evaluar modelos de lenguaje. Estos datasets cubren una variedad de tareas y dominios, lo que facilita a los investigadores y desarrolladores encontrar datos relevantes para sus proyectos. Por supuesto también podríamos usar datos propios o de empresa.\n",
    "\n",
    "\n",
    "**Principales características de los datasets de Hugging Face**\n",
    "\n",
    "\n",
    "1. **Variedad de Tareas**. Los datasets de Hugging Face cubren una amplia gama de tareas de NLP, incluyendo:\n",
    "\n",
    "    + Clasificación de Texto: Etiquetado de textos en categorías específicas.\n",
    "    + Análisis de Sentimiento: Determinación de la polaridad (positiva, negativa, neutral) de un texto.\n",
    "    + Traducción Automática: Conversión de texto de un idioma a otro.\n",
    "    + Generación de Texto: Creación de texto coherente y relevante a partir de una entrada dada.\n",
    "    + Respuesta a Preguntas: Extracción de respuestas específicas de un texto dado.\n",
    "    + Resumen de Texto: Generación de resúmenes concisos de textos más largos.\n",
    "    + Reconocimiento de Entidades Nombradas (NER): Identificación y clasificación de entidades como personas, lugares y organizaciones en un texto.\n",
    "\n",
    "\n",
    "2. **Formatos Estándar**. Los datasets están disponibles en formatos estándar como JSON, CSV y otros, lo que facilita su integración y uso en diferentes proyectos y herramientas.\n",
    "\n",
    "\n",
    "3. **Accesibilidad y Uso**. Hugging Face proporciona una API fácil de usar que permite a los desarrolladores acceder a estos datasets directamente desde sus scripts o entornos de desarrollo. Por ejemplo, utilizando la biblioteca datasets de Hugging Face, se puede cargar un dataset con unas pocas líneas de código.\n",
    "\n",
    "\n",
    "4. **Documentación y Ejemplos**. Cada dataset en la plataforma Hugging Face viene con documentación detallada y ejemplos de uso. Esto incluye descripciones de las columnas, ejemplos de datos, y métricas utilizadas para la evaluación.\n",
    "\n",
    "\n",
    "5. **Colaboración y Contribuciones**. La plataforma permite a los usuarios contribuir con sus propios datasets, ampliando continuamente la colección disponible. Esto fomenta una comunidad colaborativa donde se pueden compartir recursos y mejores prácticas.\n",
    "\n",
    "\n",
    "\n",
    "**Ejemplos de datasets populares en Hugging Face**\n",
    "\n",
    "\n",
    "+ GLUE (General Language Understanding Evaluation): Un conjunto para evaluar modelos de comprensión del lenguaje, que incluye diversas tareas como clasificación de textos y emparejamiento de oraciones.\n",
    "\n",
    "+ SQuAD (Stanford Question Answering Dataset): Un conjunto de datos para la tarea de respuesta a preguntas, donde el modelo debe responder preguntas basadas en párrafos de Wikipedia.\n",
    "\n",
    "+ MNLI (Multi-Genre Natural Language Inference): Un dataset para la tarea de inferencia natural del lenguaje, donde se debe determinar si una premisa implica, contradice o es neutral respecto a una hipótesis.\n",
    "\n",
    "\n",
    "**Beneficios de usar datasets de Hugging Face**\n",
    "\n",
    "\n",
    "+ Acceso a Datos de Alta Calidad. Los datasets de Hugging Face suelen ser bien curados y utilizados ampliamente en la investigación y desarrollo de modelos de NLP.\n",
    "\n",
    "+ Facilidad de Uso. La integración con la biblioteca datasets facilita la carga y manipulación de datos, ahorrando tiempo y esfuerzo a los desarrolladores.\n",
    "\n",
    "+ Comunidad Activa. La plataforma Hugging Face cuenta con una comunidad activa que continuamente contribuye con nuevos datasets y mejora los existentes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96409a50",
   "metadata": {},
   "source": [
    "## 3 - Ejemplos de datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e15d4cf",
   "metadata": {},
   "source": [
    "Los datasets se descargan en local en la ruta `~/.cache/huggingface/datasets`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2cc003c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:228: RuntimeWarning: pyarrow.lib.Tensor size changed, may indicate binary incompatibility. Expected 64 from C header, got 80 from PyObject\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2efeafc",
   "metadata": {},
   "source": [
    "### 3.1 - GLUE (General Language Understanding Evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa469c9c",
   "metadata": {},
   "source": [
    "El primer ejemplo es el conjunto de datos MRPC (Microsoft Research Paraphrase Corpus), introducido en el [paper](https://aclanthology.org/I05-5002.pdf) por William B. Dolan y Chris Brockett, llamado [GLUE](https://gluebenchmark.com/). El conjunto de datos consiste en 5,801 pares de oraciones, con una etiqueta que indica si son paráfrasis o no, es decir, si ambas oraciones significan lo mismo. El dataset es pequeño, pesa aproximadamente 1.5Mb. Vamos a cargarlo y ver qué contiene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0af6f345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "        num_rows: 3668\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "        num_rows: 408\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "        num_rows: 1725\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glue_dataset = load_dataset('glue', 'mrpc')\n",
    "\n",
    "glue_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c59f028",
   "metadata": {},
   "source": [
    "Vemos que el objeto DatasetDict contiene un paquete de entrenamiento con 3668 filas, un paquete de validación con 408 filas y un paquete de testeo con 1725 filas, todos ellos tienen cuatro columnas (sentence1, sentence2, label, e idx), las dos frases que se van a comparar, la etiqueta (0 o 1) y el índice de fila. La etiqueta 0 se corresponde con \"No equivalente\" y la etiqueta 1 se corresponde con \"Equivalente\". Veamos el primer registro del paquete de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18501643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence1': 'Amrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence .',\n",
       " 'sentence2': 'Referring to him as only \" the witness \" , Amrozi accused his brother of deliberately distorting his evidence .',\n",
       " 'label': 1,\n",
       " 'idx': 0}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glue_dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2832d060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence1': Value(dtype='string', id=None),\n",
       " 'sentence2': Value(dtype='string', id=None),\n",
       " 'label': ClassLabel(names=['not_equivalent', 'equivalent'], id=None),\n",
       " 'idx': Value(dtype='int32', id=None)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glue_dataset['train'].features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8dbf80",
   "metadata": {},
   "source": [
    "Con estos datos podemos ajustar un modelo para detectar equivalencias entre frases. Luego lo haremos, pero veamos primero otro conjunto de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b310062e",
   "metadata": {},
   "source": [
    "### 3.2 - Análisis de sentimiento en Twitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90676379",
   "metadata": {},
   "source": [
    "Este dataset está creado por [MTEB](https://huggingface.co/datasets/mteb/tweet_sentiment_extraction) (Massive Text Embeddings Benchmark) y está diseñado para clasificar el sentimiento de los tweets en negativo, neutral o positivo. Este dataset es un poco más grande que el anterior, tiene un peso de unos 11Mb. Vamos a ver como es este dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c35f0a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_dataset = load_dataset('mteb/tweet_sentiment_extraction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "018d9ab8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'text', 'label', 'label_text'],\n",
       "        num_rows: 27481\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'text', 'label', 'label_text'],\n",
       "        num_rows: 3534\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc9dc46",
   "metadata": {},
   "source": [
    "En este caso, el dataset está dividido en en dos paquetes, el paquete de entrenamiento con 27481 filas y el paquete de testeo con 3534 filas. Las cuatro columnas que tiene son el id, identificador único de fila, text, que es el texto de la frase del tweet, label, que es la etiqueta numérica y label_text, que es la etiqueta en formato string. La etiqueta 0 se corresponde con negativo, la etiqueta 1 se corresponde con neutral y la etiqueta 2 se corresponde con positivo. Veamos, igual que antes, un registro de este dataset y la descripción de las columnas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36bc556f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'cb774db0d1',\n",
       " 'text': ' I`d have responded, if I were going',\n",
       " 'label': 1,\n",
       " 'label_text': 'neutral'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63602ae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': Value(dtype='string', id=None),\n",
       " 'text': Value(dtype='string', id=None),\n",
       " 'label': Value(dtype='int64', id=None),\n",
       " 'label_text': Value(dtype='string', id=None)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_dataset['train'].features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c69b403",
   "metadata": {},
   "source": [
    "Existen datasets para múltiples tareas dentro del hub de hugging face. Nosotros usaremos estos dos datasets para realizar un ajuste fino en un modelo BERT que ya hemos utilizado anteriormente para clasificación de texto."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d13f80e",
   "metadata": {},
   "source": [
    "## 4 - Fine Tuning GLUE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed882d98",
   "metadata": {},
   "source": [
    "Ahora que tenemos los datos listos, vamos al proceso del ajuste fino de un modelo. Usaremos un modelo BERT para las dos tareas que tenemos, comparación de oraciones y análisis de sentimiento de tweets. Primero realizamos la tarea de comparar dos oraciones que tiene dos etiquetas, es un clasificador binario, 0 o 1. Ahora carguemos el tokenizador y modelo como ya hemos hecho anteriormente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94f0235",
   "metadata": {},
   "source": [
    "### 4.1 - Tokenizador y Modelo BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "913aef35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87433571",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = 'bert-base-uncased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70324a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ia/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertTokenizerFast(name_or_path='bert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizador = AutoTokenizer.from_pretrained(modelo)\n",
    "\n",
    "tokenizador"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583e3f90",
   "metadata": {},
   "source": [
    "Veamos los parámetros y configuraciones del `BertTokenizerFast`:\n",
    "\n",
    "\n",
    "+ name_or_path='bert-base-uncased': Especifica el nombre del modelo o la ruta desde donde se carga el tokenizador. \n",
    "\n",
    "\n",
    "+ vocab_size=30522: Define el tamaño del vocabulario del tokenizador. El tokenizador tiene 30522 tokens únicos en su vocabulario.\n",
    "\n",
    "\n",
    "+ model_max_length=512: Establece la longitud máxima de las secuencias de tokens que el modelo puede procesar. El tokenizador truncará las secuencias de tokens que excedan los 512 tokens.\n",
    "\n",
    "\n",
    "+ is_fast=True: Indica si se está utilizando la versión rápida del tokenizador.\n",
    "\n",
    "\n",
    "+ padding_side='right': Define en qué lado de la secuencia se añade el padding, \"right\" significa que el padding se añade al final de la secuencia.\n",
    "\n",
    "\n",
    "+ truncation_side='right': Define en qué lado de la secuencia se realiza el truncamiento, \"right\" significa que el truncamiento se realiza al final de la secuencia.\n",
    "\n",
    "\n",
    "+ special_tokens: Define los tokens especiales utilizados por el tokenizador. \n",
    "    + `[UNK]` para tokens desconocidos.\n",
    "    + `[SEP]` para separar secuencias.\n",
    "    + `[PAD]` para padding.\n",
    "    + `[CLS]` al inicio de cada secuencia para tareas de clasificación.\n",
    "    + `[MASK]` para el modelado de lenguaje enmascarado.\n",
    "\n",
    "\n",
    "+ clean_up_tokenization_spaces=True: Indica si se deben limpiar los espacios después de la tokenización. True significa que se eliminarán espacios innecesarios para mantener el texto limpio.\n",
    "\n",
    "\n",
    "+ added_tokens_decoder: Este es un diccionario que mapea índices a tokens añadidos manualmente con sus configuraciones específicas.\n",
    "    + rstrip=False: No elimina espacios al final del token.\n",
    "    + lstrip=False: No elimina espacios al inicio del token.\n",
    "    + single_word=False: El token no está restringido a una sola palabra.\n",
    "    + normalized=False: No normaliza el token.\n",
    "    + special=True: Indica que es un token especial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30072b33",
   "metadata": {},
   "source": [
    "Ahora cargamos el modelo BERT y vemos su estructura:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "753628c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo_bert = AutoModelForSequenceClassification.from_pretrained(modelo, num_labels=2)\n",
    "\n",
    "modelo_bert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60c7baf",
   "metadata": {},
   "source": [
    "El modelo BertForSequenceClassification es una variante de BERT específicamente adaptada para tareas de clasificación de secuencias. Este modelo toma una secuencia de texto y la clasifica en una de las categorías definidas. \n",
    "\n",
    "\n",
    "**Componentes de BertForSequenceClassification**:\n",
    "\n",
    "\n",
    "1. bert: La parte principal del modelo que contiene la arquitectura básica de BERT. Sus componentes son:\n",
    "+ embeddings:\n",
    "    + word_embeddings: Matriz de embeddings para convertir tokens en vectores de 768 dimensiones. Tamaño del vocabulario: 30522.\n",
    "    + position_embeddings: Embeddings para posiciones en la secuencia, permite al modelo distinguir la posición de cada token.\n",
    "    + token_type_embeddings: Embeddings para tipos de tokens, utilizados para tareas con múltiples secuencias, por ejemplo, preguntas y respuestas.\n",
    "    + LayerNorm: Normalización por capas para estabilizar y acelerar el entrenamiento.\n",
    "    + dropout: Regularización para prevenir el sobreajuste, con una tasa del 10%.\n",
    "\n",
    "\n",
    "2. encoder: El componente que procesa las secuencias de tokens a través de varias capas de transformaciones. Sus componentes son:\n",
    "+ layer: Conjunto de 12 capas, BertLayer, cada una con los siguientes subcomponentes:\n",
    "    + attention:\n",
    "        + BertSelfAttention: Mecanismo de atención propia, que incluye transformaciones lineales para consultas (query), claves (key) y valores (value), todas con dimensiones de entrada y salida de 768.\n",
    "        + dropout: Regularización con una tasa del 10%.\n",
    "    + output:\n",
    "        + dense: Transformación lineal de los valores de atención.\n",
    "        + LayerNorm: Normalización por capas.\n",
    "        + dropout: Regularización.\n",
    "    + intermediate:\n",
    "        + dense: Transformación lineal que expande las dimensiones a 3072.\n",
    "        + intermediate_act_fn: Función de activación GELU.\n",
    "    + output:\n",
    "        + dense: Transformación lineal que reduce las dimensiones de nuevo a 768.\n",
    "        + LayerNorm: Normalización por capas.\n",
    "        + dropout: Regularización.\n",
    "\n",
    "\n",
    "3. pooler: Componente que convierte la representación de la secuencia en una representación fija.\n",
    "+ dense: Transformación lineal de la representación del token `[CLS]`.\n",
    "+ activation: Función de activación Tanh.\n",
    "\n",
    "\n",
    "4. dropout: Regularización adicional aplicada antes de la capa de clasificación final.\n",
    "\n",
    "\n",
    "5. classifier: La capa final que realiza la clasificación.\n",
    "+ Linear: Transformación lineal que convierte las 768 dimensiones de la salida del pooler en 2 dimensiones, asumiendo que la tarea tiene 2 clases de salida.\n",
    "+ bias: Sesgo añadido a la transformación lineal.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Función general del modelo**:\n",
    "\n",
    "\n",
    "El modelo BertForSequenceClassification sigue estos pasos para clasificar una secuencia de texto:\n",
    "\n",
    "1. Tokenización y Embedding: El texto de entrada se tokeniza y convierte en embeddings que incorporan información de los tokens, sus posiciones y sus tipos.\n",
    "\n",
    "2. Codificación: Los embeddings pasan a través del encoder BERT, que utiliza múltiples capas de autoatención y transformaciones para generar representaciones ricas de las secuencias.\n",
    "\n",
    "3. Pooling: La representación del token `[CLS]`, usado como un resumen de la secuencia, se pasa por una capa densa y una activación Tanh para obtener una representación fija de la secuencia.\n",
    "\n",
    "4. Clasificación: La representación fija se pasa a través de una capa de dropout y finalmente a una capa de clasificación lineal que produce la predicción de clase.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c97b159",
   "metadata": {},
   "source": [
    "### 4.2 - Tokenizando el dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6828cd28",
   "metadata": {},
   "source": [
    "Ahora vamos a tokenizar el dataset para que el modelo pueda entender la entrada que le damos. Se realiza la tokenización para ambas frases del dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02edc505",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_dataset = glue_dataset.map(lambda x: tokenizador(x['sentence1'],\n",
    "                                                       x['sentence2'],\n",
    "                                                       truncation=True\n",
    "                                                      ),\n",
    "                                \n",
    "                                batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "236c5fe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 3668\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 408\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 1725\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2a85ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 2572, 3217, 5831, 5496, 2010, 2567, 1010, 3183, 2002, 2170, 1000, 1996, 7409, 1000, 1010, 1997, 9969, 4487, 23809, 3436, 2010, 3350, 1012, 102, 7727, 2000, 2032, 2004, 2069, 1000, 1996, 7409, 1000, 1010, 2572, 3217, 5831, 5496, 2010, 2567, 1997, 9969, 4487, 23809, 3436, 2010, 3350, 1012, 102]\n"
     ]
    }
   ],
   "source": [
    "print(token_dataset['train'][0]['input_ids'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c03d2c",
   "metadata": {},
   "source": [
    "### 4.3 - Data Collator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ef3fc4",
   "metadata": {},
   "source": [
    "Un \"data collator\" es una herramienta o función utilizada en el procesamiento de datos para modelos de aprendizaje automático, especialmente en el contexto del NLP. Su principal función es preparar lotes de datos (batches) de una manera que los modelos puedan consumir eficientemente durante el entrenamiento o la inferencia.\n",
    "\n",
    "\n",
    "**Funciones Principales de un Data Collator:**\n",
    "\n",
    "\n",
    "1. Agrupación de Datos en Lotes: El data collator toma un conjunto de ejemplos individuales y los agrupa en lotes del tamaño especificado. Esto es esencial para el entrenamiento en paralelo y para aprovechar la aceleración de hardware como las GPUs.\n",
    "\n",
    "\n",
    "2. Alineación de Secuencias: En tareas de NLP, los textos pueden tener diferentes longitudes. El data collator a menudo ajusta estas longitudes para que todas las secuencias en un lote tengan la misma longitud, usualmente mediante padding (relleno) para que se ajusten al tamaño máximo permitido por el modelo.\n",
    "\n",
    "\n",
    "3. Manejo de Máscaras de Atención: Al alinear las secuencias con padding, el data collator también genera máscaras de atención que indican cuáles tokens son padding y cuáles son datos reales. Esto permite que el modelo ignore los tokens de padding durante el procesamiento.\n",
    "\n",
    "\n",
    "4. Preprocesamiento Específico de la Tarea: Para ciertas tareas específicas, el data collator puede realizar operaciones adicionales, como la creación de tokens enmascarados para tareas de modelado de lenguaje enmascarado.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Beneficios del Uso de Data Collators**:\n",
    "\n",
    "\n",
    "+ Eficiencia: Facilita la creación de lotes de datos que los modelos pueden procesar eficientemente.\n",
    "\n",
    "\n",
    "+ Flexibilidad: Permite personalizar el preprocesamiento de datos para adaptarse a diferentes tareas y modelos.\n",
    "\n",
    "\n",
    "+ Compatibilidad: Garantiza que los datos se alineen correctamente con los requerimientos de entrada del modelo, lo que es crucial para un entrenamiento y evaluación efectivos.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2fe0da",
   "metadata": {},
   "source": [
    "DataCollatorWithPadding se utiliza para alinear las secuencias de entrada mediante padding y generar las máscaras de atención necesarias para que el Trainer funcione correctamente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3768e134",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32f05c99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataCollatorWithPadding(tokenizer=BertTokenizerFast(name_or_path='bert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}, padding=True, max_length=None, pad_to_multiple_of=None, return_tensors='pt')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizador)\n",
    "\n",
    "data_collator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9af7e46",
   "metadata": {},
   "source": [
    "### 4.4 - Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfd1c42",
   "metadata": {},
   "source": [
    "El Trainer es una clase que simplifica significativamente el proceso de entrenamiento y evaluación de modelos de NLP. Proporciona una interfaz altamente abstraída para manejar las tareas comunes en el entrenamiento de modelos, como el bucle de entrenamiento, la evaluación, la optimización y el manejo de datos, permitiendo a los desarrolladores enfocarse más en la configuración del modelo y menos en los detalles de implementación.\n",
    "\n",
    "**Principales Funcionalidades del Trainer**:\n",
    "\n",
    "1. **Entrenamiento**:\n",
    "\n",
    "\n",
    "+ Facilita el entrenamiento del modelo en los datos proporcionados, gestionando automáticamente los bucles de entrenamiento y las actualizaciones de parámetros.\n",
    "+ Admite técnicas avanzadas como el aprendizaje por lotes, el entrenamiento distribuido y el ajuste de hiperparámetros.\n",
    "\n",
    "\n",
    "\n",
    "2. **Evaluación**:\n",
    "\n",
    "\n",
    "+ Permite evaluar el modelo en un conjunto de datos de validación para monitorear su rendimiento durante el entrenamiento.\n",
    "+ Genera métricas de evaluación, como precisión, recall o F1-score.\n",
    "\n",
    "\n",
    "\n",
    "3. **Optimización**:\n",
    "\n",
    "+ Integra optimizadores estándar y avanzados, como AdamW, y permite la configuración de estrategias de ajuste de tasa de aprendizaje.\n",
    "\n",
    "\n",
    "\n",
    "4. **Gestión de Datos**:\n",
    "\n",
    "\n",
    "+ Compatible con los datasets de Hugging Face, permitiendo una fácil carga y preprocesamiento de datos.\n",
    "+ Soporta el uso de collators de datos personalizados, como DataCollatorWithPadding.\n",
    "\n",
    "\n",
    "\n",
    "5. **Checkpointing**:\n",
    "\n",
    "\n",
    "+ Guarda automáticamente puntos de control (checkpoints) del modelo durante el entrenamiento para permitir la reanudación y la recuperación del progreso."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e2eef6",
   "metadata": {},
   "source": [
    "Para usar el Trainer, tenemos que que definir los parámetros y opciones del entrenamiento. Para ello tenemos la clase TrainingArguments. Esta clase permite especificar una amplia gama de configuraciones que controlan diversos aspectos del proceso de entrenamiento, como la tasa de aprendizaje, el tamaño de los lotes, las estrategias de evaluación y muchas otras. \n",
    "\n",
    "\n",
    "**Principales Componentes de TrainingArguments**\n",
    "\n",
    "\n",
    "1. **Directorio de salida**:\n",
    "\n",
    "+ output_dir: Especifica el directorio donde se guardarán los modelos entrenados y los resultados.\n",
    "\n",
    "\n",
    "2. **Parámetros de entrenamiento**:\n",
    "\n",
    "+ per_device_train_batch_size: Tamaño del lote de entrenamiento por dispositivo (CPU/GPU/TPU).\n",
    "+ per_device_eval_batch_size: Tamaño del lote de evaluación por dispositivo.\n",
    "+ learning_rate: Tasa de aprendizaje utilizada por el optimizador.\n",
    "+ weight_decay: Factor de decaimiento de pesos para la regularización.\n",
    "+ num_train_epochs: Número de épocas, iteraciones completas sobre el conjunto de datos de entrenamiento.\n",
    "+ max_steps: Número máximo de pasos de entrenamiento. Si se especifica, anula num_train_epochs.\n",
    "\n",
    "\n",
    "3. **Estrategias de evaluación y guardado**:\n",
    "\n",
    "+ evaluation_strategy: Estrategia de evaluación, \"no\" para ninguna evaluación, \"steps\" para evaluar cada ciertos pasos, \"epoch\" para evaluar al final de cada época.\n",
    "+ save_strategy: Estrategia de guardado de puntos de control (\"no\", \"steps\", \"epoch\").\n",
    "+ logging_strategy: Estrategia de registro (\"no\", \"steps\", \"epoch\").\n",
    "+ eval_steps: Número de pasos entre evaluaciones, si evaluation_strategy está configurado en \"steps\".\n",
    "+ save_steps: Número de pasos entre guardados de puntos de control, si save_strategy está configurado en \"steps\".\n",
    "+ logging_steps: Número de pasos entre registros de información.\n",
    "\n",
    "\n",
    "4. **Configuraciones de desempeño**:\n",
    "\n",
    "+ gradient_accumulation_steps: Número de pasos de acumulación de gradientes antes de realizar una actualización de los parámetros.\n",
    "+ fp16: Habilita la precisión mixta, en 16 bits, para reducir el uso de memoria y acelerar el entrenamiento.\n",
    "+ dataloader_num_workers: Número de subprocesos a utilizar para cargar datos.\n",
    "\n",
    "\n",
    "5. **Otras opciones útiles**:\n",
    "\n",
    "+ warmup_steps: Número de pasos de calentamiento para la programación de la tasa de aprendizaje.\n",
    "+ logging_dir: Directorio para guardar los registros de entrenamiento.\n",
    "+ save_total_limit: Número máximo de puntos de control a guardar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2987b6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5cb815a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "arg_training = TrainingArguments(output_dir='training/glue-trainer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "60f9352e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainingArguments(\n",
      "_n_gpu=1,\n",
      "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "batch_eval_metrics=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_persistent_workers=False,\n",
      "dataloader_pin_memory=True,\n",
      "dataloader_prefetch_factor=None,\n",
      "ddp_backend=None,\n",
      "ddp_broadcast_buffers=None,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "dispatch_batches=None,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=False,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_do_concat_batches=True,\n",
      "eval_on_start=False,\n",
      "eval_steps=None,\n",
      "eval_strategy=no,\n",
      "eval_use_gather_object=False,\n",
      "evaluation_strategy=None,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "gradient_checkpointing_kwargs=None,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_always_push=False,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "include_num_input_tokens_seen=False,\n",
      "include_tokens_per_second=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=5e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=0,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=training/glue-trainer/runs/Oct29_10-28-46_MB-17.local,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=500,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_kwargs={},\n",
      "lr_scheduler_type=linear,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "neftune_noise_alpha=None,\n",
      "no_cuda=False,\n",
      "num_train_epochs=3.0,\n",
      "optim=adamw_torch,\n",
      "optim_args=None,\n",
      "optim_target_modules=None,\n",
      "output_dir=training/glue-trainer,\n",
      "overwrite_output_dir=False,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=8,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=['tensorboard'],\n",
      "restore_callback_states_from_checkpoint=False,\n",
      "resume_from_checkpoint=None,\n",
      "run_name=training/glue-trainer,\n",
      "save_on_each_node=False,\n",
      "save_only_model=False,\n",
      "save_safetensors=True,\n",
      "save_steps=500,\n",
      "save_strategy=steps,\n",
      "save_total_limit=None,\n",
      "seed=42,\n",
      "skip_memory_metrics=True,\n",
      "split_batches=None,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torch_empty_cache_steps=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_cpu=False,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(arg_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "08dbd2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "entrenador = Trainer(model=modelo_bert,\n",
    "                     tokenizer=tokenizador,\n",
    "                     train_dataset=token_dataset['train'],\n",
    "                     eval_dataset=token_dataset['validation'],\n",
    "                     args=arg_training,\n",
    "                     data_collator=data_collator\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f7666c5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1377' max='1377' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1377/1377 04:15, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.552200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.313600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1377, training_loss=0.36224605141988075, metrics={'train_runtime': 256.3171, 'train_samples_per_second': 42.931, 'train_steps_per_second': 5.372, 'total_flos': 405114969714960.0, 'train_loss': 0.36224605141988075, 'epoch': 3.0})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entrenador.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb7d128",
   "metadata": {},
   "source": [
    "### 4.5 - Predicción y evaluación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2557643a",
   "metadata": {},
   "source": [
    "Ahora que ya tenemos el modelo ajustado con el dataset, podemos realizar predicciones y también evaluar cómo de bien funciona el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "572806f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([-3.4751434,  3.0385222], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicciones = entrenador.predict(token_dataset['test'])\n",
    "\n",
    "predicciones.predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9bbdee7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# etiquetas\n",
    "\n",
    "etiquetas = predicciones.label_ids\n",
    "\n",
    "etiquetas[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b6825f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "predicciones = np.argmax(predicciones.predictions, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5ee88ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1725,) (1725,)\n"
     ]
    }
   ],
   "source": [
    "print(predicciones.shape, etiquetas.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "42efed86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicciones[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1591808",
   "metadata": {},
   "source": [
    "Ahora que tenemos las predicciones y la verdad, podemos realizar la evaluación. Calculamos el acierto, accuracy, y el [f1-score](https://en.wikipedia.org/wiki/F-score), una métrica utilizada en la evaluación de modelos de clasificación, especialmente cuando se trabaja con datos desbalanceados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dd04d499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.7931758165359497,\n",
       " 'eval_runtime': 2.1957,\n",
       " 'eval_samples_per_second': 185.817,\n",
       " 'eval_steps_per_second': 23.227,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entrenador.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6f879d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importamos las métricas de evaluación\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "169fc0b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8284057971014492, 'f1': 0.8762541806020067}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculamos las métricas\n",
    "\n",
    "{'accuracy':accuracy_score(predicciones, etiquetas), \n",
    " 'f1':f1_score(predicciones, etiquetas)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3f3a1c",
   "metadata": {},
   "source": [
    "Podemos crear una función de evaluación con estas métricas para pasársela al entrenador y poder evaluar directamente desde el entrenador e incluso evaluar durante el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "728c6088",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluacion(modelo_preds):\n",
    "    \n",
    "    \"\"\"\n",
    "    Función para obtener la métricas de evaluación.\n",
    "    \n",
    "    Params:\n",
    "    + modelo_preds: transformers.trainer_utils.PredictionOutput, predicciones del modelo y etiquetas.\n",
    "    \n",
    "    Return:\n",
    "    dict: diccionario con keys accuracy y f1-score y sus valores respectivos.\n",
    "    \"\"\"\n",
    "    \n",
    "    preds, etiquetas = modelo_preds\n",
    "    \n",
    "    preds = np.argmax(preds, axis=-1)\n",
    "        \n",
    "    return {'accuracy': accuracy_score(preds, etiquetas), \n",
    "            'f1': f1_score(preds, etiquetas)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9977bd07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ia/lib/python3.9/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# argumento de entrenamiento\n",
    "\n",
    "args_entrenamiento = TrainingArguments(output_dir='training/glue-trainer', \n",
    "                                       evaluation_strategy='steps',\n",
    "                                       logging_steps=100,\n",
    "                                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d948ec99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entrenador con función de métricas\n",
    "\n",
    "entrenador = Trainer(model=modelo_bert,\n",
    "                     args=args_entrenamiento,\n",
    "                     train_dataset=token_dataset['train'],\n",
    "                     eval_dataset=token_dataset['validation'],\n",
    "                     data_collator=data_collator,\n",
    "                     tokenizer=tokenizador,\n",
    "                     compute_metrics=evaluacion\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9ecad93a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1377' max='1377' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1377/1377 04:35, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.241900</td>\n",
       "      <td>0.795381</td>\n",
       "      <td>0.821078</td>\n",
       "      <td>0.871705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.192700</td>\n",
       "      <td>0.876446</td>\n",
       "      <td>0.816176</td>\n",
       "      <td>0.873524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.190000</td>\n",
       "      <td>0.979941</td>\n",
       "      <td>0.779412</td>\n",
       "      <td>0.830827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.207000</td>\n",
       "      <td>0.937371</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.876289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.129900</td>\n",
       "      <td>0.963345</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.880399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.083300</td>\n",
       "      <td>0.796648</td>\n",
       "      <td>0.843137</td>\n",
       "      <td>0.886525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.103800</td>\n",
       "      <td>0.860607</td>\n",
       "      <td>0.835784</td>\n",
       "      <td>0.884682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.073800</td>\n",
       "      <td>0.993176</td>\n",
       "      <td>0.816176</td>\n",
       "      <td>0.874372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.137100</td>\n",
       "      <td>0.708059</td>\n",
       "      <td>0.843137</td>\n",
       "      <td>0.888502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.027200</td>\n",
       "      <td>0.968943</td>\n",
       "      <td>0.843137</td>\n",
       "      <td>0.893333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.037900</td>\n",
       "      <td>1.013614</td>\n",
       "      <td>0.840686</td>\n",
       "      <td>0.890017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.076000</td>\n",
       "      <td>0.964230</td>\n",
       "      <td>0.840686</td>\n",
       "      <td>0.889267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.054800</td>\n",
       "      <td>0.911610</td>\n",
       "      <td>0.852941</td>\n",
       "      <td>0.897260</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1377, training_loss=0.11643309271153801, metrics={'train_runtime': 276.0866, 'train_samples_per_second': 39.857, 'train_steps_per_second': 4.988, 'total_flos': 405114969714960.0, 'train_loss': 0.11643309271153801, 'epoch': 3.0})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# entrenamiento\n",
    "\n",
    "entrenador.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d9e745ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.9068790674209595,\n",
       " 'eval_accuracy': 0.8553921568627451,\n",
       " 'eval_f1': 0.8987993138936535,\n",
       " 'eval_runtime': 1.7665,\n",
       " 'eval_samples_per_second': 230.96,\n",
       " 'eval_steps_per_second': 28.87,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluación directa desde el entrenador, ahora con acierto y f1\n",
    "\n",
    "entrenador.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d53f04",
   "metadata": {},
   "source": [
    "### 4.6 - Guardado del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcf69d8",
   "metadata": {},
   "source": [
    "Una vez que hemos ajustado el modelo, podemos guardarlo de la siguiente manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d95bb4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# guardado en la ruta dada\n",
    "\n",
    "entrenador.save_model('training/glue_bert')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724910a5",
   "metadata": {},
   "source": [
    "## 5 - Fine Tuning Análisis de Sentimiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a10bf72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# librerias\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "from transformers import (AutoTokenizer, \n",
    "                          AutoModelForSequenceClassification, \n",
    "                          DataCollatorWithPadding,\n",
    "                          Trainer, \n",
    "                          TrainingArguments)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ec849194",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since mteb/tweet_sentiment_extraction couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'default' at /Users/tecnico.IA/.cache/huggingface/datasets/mteb___tweet_sentiment_extraction/default/0.0.0/62146448f05be9e52a36b8ee9936447ea787eede (last modified on Thu May 23 08:37:09 2024).\n"
     ]
    }
   ],
   "source": [
    "# dataset\n",
    "\n",
    "tweet_dataset = load_dataset('mteb/tweet_sentiment_extraction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6ae690f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definimos el modelo \n",
    "\n",
    "modelo = 'bert-base-uncased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "95b90ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ia/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# con este objeto se vectorizan las palabras\n",
    "\n",
    "tokenizador = AutoTokenizer.from_pretrained(modelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "61edb68c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# iniciamos el modelo BERT\n",
    "\n",
    "modelo_bert = AutoModelForSequenceClassification.from_pretrained(modelo, num_labels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "74881f3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e934433df7f14a34ad54a17c508079b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/27481 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "782f3e6d58434a5abfc996c82b82acb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3534 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tokenizar el dataset\n",
    "\n",
    "token_dataset = tweet_dataset.map(lambda x: tokenizador(x['text'], \n",
    "                                                        truncation=True), \n",
    "                                  batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8e24b52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizador)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "197c9b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ia/lib/python3.9/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# argumentos de entrenamiento\n",
    "\n",
    "args_entrenamiento = TrainingArguments(output_dir='training/sentiment-trainer', \n",
    "                                       evaluation_strategy='steps',\n",
    "                                       logging_steps=1000,\n",
    "                                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bafa8325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# función de evaluación\n",
    "\n",
    "def evaluacion(model_preds):\n",
    "    \n",
    "    \"\"\"\n",
    "    Función para obtener la métricas de evaluación.\n",
    "    \n",
    "    Params:\n",
    "    + modelo_preds: transformers.trainer_utils.PredictionOutput, predicciones del modelo y etiquetas.\n",
    "    \n",
    "    Return:\n",
    "    dict: diccionario con keys accuracy y f1-score y sus valores respectivos. \n",
    "    Se añade macro al f1-score porque no es un clasificador binario, sino que hay 3 clases.\n",
    "    \"\"\"\n",
    "    \n",
    "    preds, labels = model_preds\n",
    "    \n",
    "    preds = np.argmax(preds, axis=-1)\n",
    "        \n",
    "    return {'accuracy': accuracy_score(preds, labels), \n",
    "            'f1': f1_score(preds, labels, average='macro')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "65366c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entrenador \n",
    "\n",
    "entrenador = Trainer(model=modelo_bert,\n",
    "                     args=args_entrenamiento,\n",
    "                     train_dataset=token_dataset['train'],\n",
    "                     eval_dataset=token_dataset['test'],\n",
    "                     data_collator=data_collator,\n",
    "                     tokenizer=tokenizador,\n",
    "                     compute_metrics=evaluacion\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9c5c55d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10308' max='10308' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10308/10308 24:41, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.682700</td>\n",
       "      <td>0.622032</td>\n",
       "      <td>0.757782</td>\n",
       "      <td>0.761352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.594300</td>\n",
       "      <td>0.653658</td>\n",
       "      <td>0.739106</td>\n",
       "      <td>0.738007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.584600</td>\n",
       "      <td>0.577226</td>\n",
       "      <td>0.773345</td>\n",
       "      <td>0.777350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.510900</td>\n",
       "      <td>0.600896</td>\n",
       "      <td>0.778721</td>\n",
       "      <td>0.782304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.436000</td>\n",
       "      <td>0.704551</td>\n",
       "      <td>0.785229</td>\n",
       "      <td>0.788299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.447300</td>\n",
       "      <td>0.592308</td>\n",
       "      <td>0.792303</td>\n",
       "      <td>0.795661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.403400</td>\n",
       "      <td>0.861037</td>\n",
       "      <td>0.785512</td>\n",
       "      <td>0.789108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.309600</td>\n",
       "      <td>0.805521</td>\n",
       "      <td>0.786078</td>\n",
       "      <td>0.789470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.305600</td>\n",
       "      <td>0.818213</td>\n",
       "      <td>0.785229</td>\n",
       "      <td>0.788976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.280700</td>\n",
       "      <td>0.868210</td>\n",
       "      <td>0.783814</td>\n",
       "      <td>0.787124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=10308, training_loss=0.4504195736228934, metrics={'train_runtime': 1482.826, 'train_samples_per_second': 55.599, 'train_steps_per_second': 6.952, 'total_flos': 1522399415750514.0, 'train_loss': 0.4504195736228934, 'epoch': 3.0})"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# entrenamiento\n",
    "\n",
    "entrenador.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9cf6c84d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.872421383857727,\n",
       " 'eval_accuracy': 0.7857951329937748,\n",
       " 'eval_f1': 0.7891127797358347,\n",
       " 'eval_runtime': 8.1958,\n",
       " 'eval_samples_per_second': 431.197,\n",
       " 'eval_steps_per_second': 53.93,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluación directa desde el entrenador\n",
    "\n",
    "entrenador.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "15c9cd4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.7857951329937748, 'f1': 0.7891127797358347}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluación manual\n",
    "\n",
    "preds = entrenador.predict(token_dataset['test'])\n",
    "\n",
    "etiquetas = preds.label_ids\n",
    "\n",
    "preds = np.argmax(preds.predictions, axis=-1)\n",
    "\n",
    "{'accuracy':accuracy_score(preds, etiquetas), \n",
    " 'f1':f1_score(preds, etiquetas, average='macro')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6b4c0301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# guardado del modelo\n",
    "\n",
    "entrenador.save_model('training/sentiment_bert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3ae358",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ia",
   "language": "python",
   "name": "ia"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Tabla de Contenidos",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "599px",
    "left": "129px",
    "top": "111.141px",
    "width": "238.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
