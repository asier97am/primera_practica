{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5f8aa50",
   "metadata": {},
   "source": [
    "# 4 - Clasificación de Tokens (NER)\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/Hack-io-AI/ai_images/main/ner.webp\" style=\"width:400px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b20be8c",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Tabla de Contenidos<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#1---Modelos-de-clasificación-de-tokens-(NER)\" data-toc-modified-id=\"1---Modelos-de-clasificación-de-tokens-(NER)-1\">1 - Modelos de clasificación de tokens (NER)</a></span></li><li><span><a href=\"#2---Pipeline-de-Transformers-para-NER\" data-toc-modified-id=\"2---Pipeline-de-Transformers-para-NER-2\">2 - Pipeline de Transformers para NER</a></span></li><li><span><a href=\"#3---Usando-el-modelo-NER\" data-toc-modified-id=\"3---Usando-el-modelo-NER-3\">3 - Usando el modelo NER</a></span><ul class=\"toc-item\"><li><span><a href=\"#3.1---Tokenizador\" data-toc-modified-id=\"3.1---Tokenizador-3.1\">3.1 - Tokenizador</a></span></li><li><span><a href=\"#3.2---Modelo-clasificador\" data-toc-modified-id=\"3.2---Modelo-clasificador-3.2\">3.2 - Modelo clasificador</a></span></li></ul></li><li><span><a href=\"#4---Combinando-pipeline-y-modelo\" data-toc-modified-id=\"4---Combinando-pipeline-y-modelo-4\">4 - Combinando pipeline y modelo</a></span></li><li><span><a href=\"#5---Visualización-de-entidades\" data-toc-modified-id=\"5---Visualización-de-entidades-5\">5 - Visualización de entidades</a></span></li><li><span><a href=\"#6---Más-modelos-NER\" data-toc-modified-id=\"6---Más-modelos-NER-6\">6 - Más modelos NER</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c164af",
   "metadata": {},
   "source": [
    "## 1 - Modelos de clasificación de tokens (NER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84346f59",
   "metadata": {},
   "source": [
    "La clasificación de tokens o NER (\"Named Entity Recognition\") que significa Reconocimiento de Entidades Nombradas, es una tarea fundamental dentro del NLP. Consiste en la identificación automática de entidades nombradas en textos y la clasificación de estas entidades en categorías predefinidas tales como nombres de personas, organizaciones, localizaciones, expresiones de tiempo, cantidades, valores monetarios, porcentajes, etc...\n",
    "\n",
    "Algunas aplicaciones del NER son:\n",
    "\n",
    "1. **Extracción de Información**:\n",
    "\n",
    "NER es una herramienta crucial para la extracción de información estructurada de textos no estructurados, lo cual es útil en muchas aplicaciones como la generación de bases de datos a partir de texto y el enriquecimiento de sistemas de información.\n",
    "\n",
    "2. **Mejora de Sistemas de Búsqueda**:\n",
    "\n",
    "Al identificar entidades específicas en documentos, NER puede mejorar la precisión de los sistemas de búsqueda permitiendo búsquedas más precisas basadas en entidades específicas.\n",
    "\n",
    "3. **Análisis de Sentimientos**:\n",
    "\n",
    "NER puede ser utilizado para identificar entidades en opiniones y reseñas y asociar sentimientos específicos con esas entidades, lo que proporciona un análisis de sentimientos más detallado y orientado.\n",
    "\n",
    "4. **Soporte para Traducción Automática**:\n",
    "\n",
    "En la traducción automática, identificar las entidades puede ayudar a mejorar la precisión de la traducción, especialmente en el caso de nombres propios y términos técnicos que no deben traducirse.\n",
    "\n",
    "5. **Cumplimiento y Monitoreo**:\n",
    "\n",
    "En el contexto legal y de cumplimiento, NER puede ser utilizado para monitorear comunicaciones en busca de menciones de entidades sensibles como nombres de empresas, productos regulados o individuos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890ecc0d",
   "metadata": {},
   "source": [
    "En el hub de [modelos](https://huggingface.co/models?sort=trending) de Hugging Face podemos encontrar los modelos de [clasificación de tokens](https://huggingface.co/models?pipeline_tag=token-classification&sort=trending) o NER. Probaremos algunos de estos modelos, comenzando por `Babelscape/wikineural-multilingual-ner`, un modelo NER capaz de manejar 9 lenguajes distintos (español, alemán, inglés, francés, italiano, holandés, portugués, polaco y ruso), aqui el [link](https://huggingface.co/Babelscape/wikineural-multilingual-ner). Este modelo está entrenado en WikiNEuRal, un conjunto de datos usado para NER derivado de Wikipedia. Por lo tanto, podría no generalizar bien en otros tipos de texto, por ejemplo, noticias. Por otro lado, los modelos entrenados solo con artículos de noticias, por ejemplo con el dataset CoNLL03, han demostrado obtener puntuaciones mucho más bajas en artículos enciclopédicos. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4076eb",
   "metadata": {},
   "source": [
    "## 2 - Pipeline de Transformers para NER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54189776",
   "metadata": {},
   "source": [
    "Primero usaremos el pipeline de transformers para usar el modelo NER. Esta es una manera fácil y cómoda de usar los modelos del hub de Hugging Face para diversas tareas, como es la clasificación de tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8af37f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b0e052c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tarea = 'ner'\n",
    "\n",
    "modelo = 'Babelscape/wikineural-multilingual-ner'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21956a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ia/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "ner_pipe = pipeline(task=tarea, model=modelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2a8070d",
   "metadata": {},
   "outputs": [],
   "source": [
    "frase = 'Mi nombre es Juan, vivo en Madrid y trabajo en BBVA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9154995",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity': 'B-PER',\n",
       "  'score': 0.7862896,\n",
       "  'index': 4,\n",
       "  'word': 'Juan',\n",
       "  'start': 13,\n",
       "  'end': 17},\n",
       " {'entity': 'B-LOC',\n",
       "  'score': 0.9997428,\n",
       "  'index': 8,\n",
       "  'word': 'Madrid',\n",
       "  'start': 27,\n",
       "  'end': 33},\n",
       " {'entity': 'B-ORG',\n",
       "  'score': 0.8988159,\n",
       "  'index': 12,\n",
       "  'word': 'BB',\n",
       "  'start': 47,\n",
       "  'end': 49},\n",
       " {'entity': 'I-ORG',\n",
       "  'score': 0.91551065,\n",
       "  'index': 13,\n",
       "  'word': '##VA',\n",
       "  'start': 49,\n",
       "  'end': 51}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_pipe(frase)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce86d40",
   "metadata": {},
   "source": [
    "La respuesta del pipeline es una lista de diccionarios. Cada uno de ellos tiene por claves:\n",
    "\n",
    "+ word: Palabra reconocida.\n",
    "+ entity: Entidad a la que pertence la palabra.\n",
    "+ score: Probabilidad de pertenencia a esa entidad.\n",
    "+ index: Indice de la palabra reconocida dentro del texto.\n",
    "+ start: Caracter de inicio de la palabra reconocida.\n",
    "+ end: Caracter final de la palabra reconocida.\n",
    "\n",
    "\n",
    "Las entidades que este modelo es capaz de reconocer son las siguientes:\n",
    "\n",
    "+ 'O': Etiqueta que se pone para una palabra fuera de la entidad (Outside)\n",
    "+ 'B-PER': Inicio de la entidad persona (Beginning Person)\n",
    "+ 'I-PER': Dentro de la entidad persona (In/Inside Person)\n",
    "+ 'B-ORG': Inicio de la entidad organización (Beginning Organization)\n",
    "+ 'I-ORG': Dentro de la entidad organización (In/Inside Organization)\n",
    "+ 'B-LOC': Inicio de la entidad localización (Beginning Location)\n",
    "+ 'I-LOC': Dentro de la entidad localización (In/Inside Location)\n",
    "+ 'B-MISC': Inicio de la entidad miscelánea (Beginning Miscelanea)\n",
    "+ 'I-MISC': Dentro de la entidad miscelánea (In/Inside Miscelanea)\n",
    "\n",
    "\n",
    "Como vemos, el pipeline separa el inicio y el interior de la entidad. Fijémosnos en la palabra BBVA. El pipeline separa la entidad nombrada \"organización\" en `B-ORG = BB` y `I-ORG = ##VA`. Este es el comportamiento que tiene por defecto el pipeline, pero lo podemos cambiar pidiéndole que agrupe las entidades con el parámetro `aggregation_strategy`. Veamos cómo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b64733bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'PER',\n",
       "  'score': 0.7862896,\n",
       "  'word': 'Juan',\n",
       "  'start': 13,\n",
       "  'end': 17},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': 0.9997428,\n",
       "  'word': 'Madrid',\n",
       "  'start': 27,\n",
       "  'end': 33},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': 0.90716326,\n",
       "  'word': 'BBVA',\n",
       "  'start': 47,\n",
       "  'end': 51}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_pipe = pipeline(task=tarea, model=modelo, aggregation_strategy='simple')\n",
    "\n",
    "ner_pipe(frase)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfd2433",
   "metadata": {},
   "source": [
    "Los cambios que hay en la respuesta del pipeline son que la key `entity` pasa a llamarse `entity_group` y desaparece la key `index`, que nos decía la posición de la palabra dentro de la frase. Aquí ya tendríamos reconocidas las entidades nombradas, el nombre de la persona, la localización y la organización.\n",
    "\n",
    "Además de `simple`, existen otras maneras de agregar las entidades, aunque en este caso no existe diferencia. Esas otras maneras son: `first`, `average` y `max`. Véamos como se hace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c706dd07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'PER',\n",
       "  'score': 0.7862896,\n",
       "  'word': 'Juan',\n",
       "  'start': 13,\n",
       "  'end': 17},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': 0.9997428,\n",
       "  'word': 'Madrid',\n",
       "  'start': 27,\n",
       "  'end': 33},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': 0.8988159,\n",
       "  'word': 'BBVA',\n",
       "  'start': 47,\n",
       "  'end': 51}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_pipe = pipeline(task=tarea, model=modelo, aggregation_strategy='first')\n",
    "\n",
    "ner_pipe(frase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30422c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'PER',\n",
       "  'score': 0.7862896,\n",
       "  'word': 'Juan',\n",
       "  'start': 13,\n",
       "  'end': 17},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': 0.9997428,\n",
       "  'word': 'Madrid',\n",
       "  'start': 27,\n",
       "  'end': 33},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': 0.45795286,\n",
       "  'word': 'BBVA',\n",
       "  'start': 47,\n",
       "  'end': 51}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_pipe = pipeline(task=tarea, model=modelo, aggregation_strategy='average')\n",
    "\n",
    "ner_pipe(frase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96f7d0d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'PER',\n",
       "  'score': 0.7862896,\n",
       "  'word': 'Juan',\n",
       "  'start': 13,\n",
       "  'end': 17},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': 0.9997428,\n",
       "  'word': 'Madrid',\n",
       "  'start': 27,\n",
       "  'end': 33},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': 0.91551065,\n",
       "  'word': 'BBVA',\n",
       "  'start': 47,\n",
       "  'end': 51}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_pipe = pipeline(task=tarea, model=modelo, aggregation_strategy='max')\n",
    "\n",
    "ner_pipe(frase)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c07de9d",
   "metadata": {},
   "source": [
    "## 3 - Usando el modelo NER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97652cb1",
   "metadata": {},
   "source": [
    "Ahora usaremos directamente el modelo y tokenizador desde transformers. Esta es una manera un poco más complicada de usar los modelos, pero nos permite construir la respuesta del modelo como a nosotros nos parezca. Veámoslo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c1a215b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3905add",
   "metadata": {},
   "source": [
    "### 3.1 - Tokenizador"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051a7cea",
   "metadata": {},
   "source": [
    "Como vimos anteriormente, un tokenizador es una herramienta para dividir el texto en tokens. Básicamante nos permite convertir las palabras en una entrada entendible por el modelo, es decir, convierte la frase que le damos en un vector para que el modelo clasificador de tokens puede realizar la extracción de entidades nombradas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ee46108",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizador = AutoTokenizer.from_pretrained(modelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56cd1a2e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizerFast(name_or_path='Babelscape/wikineural-multilingual-ner', vocab_size=119547, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizador"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2657339",
   "metadata": {},
   "source": [
    "Al igual que en el tokenizador de análisis de sentimiento, los tokens especiales son: [PAD], [UNK], [CLS], [SEP] y [MASK]. El tamaño del vocabulario de este tokenizador es mayor que del que usamos con el análisis de sentimiento, sin embargo funciona básicamente de la misma manera. Usemos ahora el tokenizador para generar el vector necesario para alimentar el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b970a67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = tokenizador(frase, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33f72fae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101, 19803, 11491, 10196, 11686,   117, 20886, 10110, 11727,   193,\n",
       "         18100, 10110, 49622, 47172,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f80d06",
   "metadata": {},
   "source": [
    "El vector que hemos creado es un diccionario, cuyas keys son:\n",
    "\n",
    "+ `input_ids`: Estos son los identificadores de los tokens que han sido convertidos del texto por un tokenizador, como tensor de pytorch.\n",
    "\n",
    "+ `token_type_ids`: Estos son identificadores que indican a qué secuencia pertenece cada token. Son útiles especialmente en tareas que involucran pares de secuencias, como preguntas y respuestas, donde los tokens de la primera secuencia podrían tener un ID 0 y los de la segunda secuencia un ID 1.\n",
    "\n",
    "+ `attention_mask`: La máscara de atención indica a BERT qué tokens deben ser procesados por los mecanismos de atención y cuáles no. Un valor de 1 significa que el token en esa posición debe ser considerado, mientras que un 0 indicaría que debe ser ignorado,."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd4e676",
   "metadata": {},
   "source": [
    "En el tensor de salida del tokenizador, el primer número 101 y el último número 102 son especiales: 101 es el ID para el token especial [CLS], que se utiliza al principio de cada secuencia de entrada en BERT para tareas de clasificación; 102 es el ID para el token especial [SEP], que se utiliza para marcar el final de una secuencia o separar distintas frases. Veamos cuales son los tokens que ha generado el tokenizador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1920ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = vector.tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9bd2290d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8f093a",
   "metadata": {},
   "source": [
    "Como vemos, se generan 15 tokens, pero tanto el primero como el último son irrelevantes, son tokens para que el modelo entienda correctamente las secuencias y no tienen nada que ver con nuestra frase. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5cdf54b",
   "metadata": {},
   "source": [
    "### 3.2 - Modelo clasificador"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da8b2ae",
   "metadata": {},
   "source": [
    "El modelo que estamos usando es un `BertForTokenClassification`, una arquitectura diseñada específicamente para tareas de clasificación de tokens. Esta variante de BERT está adaptada para asignar una etiqueta a cada token individual en una secuencia de entrada, lo que es esencial en tareas donde se necesita identificar y clasificar partes específicas del texto.\n",
    "\n",
    "Sus componentes principales son:\n",
    "\n",
    "1. BERT Model: Utiliza la arquitectura de BERT, que es un modelo de transformers basado en la técnica de atención. BERT procesa la entrada completa en una sola vez (procesamiento paralelo) y es capaz de capturar el contexto de cada palabra desde ambas direcciones (bidireccional).\n",
    "2. Capa de Clasificación: Sobre la salida de BERT, BertForTokenClassification añade una capa lineal que proyecta cada vector de características del token (típicamente de tamaño 768 en BERT base) a un espacio de características más pequeño que corresponde al número de etiquetas en el conjunto de datos de entrenamiento. Por ejemplo, si un modelo se entrena para reconocer entidades como personas, organizaciones y ubicaciones, la capa de clasificación mapeará la salida de BERT a estos tres tipos más una etiqueta adicional para tokens que no son parte de una entidad relevante.\n",
    "\n",
    "Su funcionamiento es el siguiente:\n",
    "\n",
    "+ Preparación de la Entrada: Los tokens de entrada se procesan con un tokenizador que los convierte en IDs de token, los cuales son interpretados por BERT.\n",
    "\n",
    "+ Embeddings: BERT convierte los IDs de tokens en embeddings, añadiendo embeddings posicionales y, si es necesario, embeddings de segmento (para diferenciar entre diferentes secuencias de tokens).\n",
    "\n",
    "+ Procesamiento por BERT: La secuencia de embeddings pasa a través de múltiples capas de transformers dentro de BERT, donde la atención auto-dirigida permite que el modelo evalúe el contexto de cada token.\n",
    "\n",
    "+ Clasificación de Tokens: La salida de cada token desde la última capa de BERT se pasa a través de la capa de clasificación lineal que predice una etiqueta para cada token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c411ea49",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_ner = AutoModelForTokenClassification.from_pretrained(modelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f283bade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForTokenClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=9, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo_ner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46bd3b3",
   "metadata": {},
   "source": [
    "Veamos cuales son los componentes principales del modelo:\n",
    "\n",
    "1. BertModel:\n",
    "Este es el modelo base de BERT que contiene los componentes principales del modelo Transformer.\n",
    "\n",
    "    + BertEmbeddings: Se encarga de convertir los tokens de entrada en vectores, que son representaciones densas y entrenables. Incluye:\n",
    "        + word_embeddings: Transforma tokens en vectores de 768 dimensiones.\n",
    "        + position_embeddings: Añade información de la posición de cada token dentro de la secuencia para mantener la noción del orden de las palabras.\n",
    "        + token_type_embeddings: Se utiliza en tareas que tienen más de una secuencia para diferenciar entre, por ejemplo, la pregunta y la respuesta.\n",
    "        + LayerNorm y Dropout: Estos son mecanismos para normalizar y evitar el sobreajuste durante el entrenamiento, respectivamente.\n",
    "\n",
    "\n",
    "2. BertEncoder:\n",
    "Contiene múltiples capas de atención y transformaciones lineales para procesar las embeddings.\n",
    "\n",
    "    + BertLayer: Cada capa, 12 en total, realiza lo siguiente:\n",
    "        + BertAttention: Maneja la atención auto-dirigida que permite al modelo prestar atención a diferentes partes de la entrada.\n",
    "        + BertSelfAttention: Calcula la atención sobre todos los tokens. Usa tres transformaciones lineales (query, key, value) para generar las puntuaciones de atención y luego combina los resultados.\n",
    "        + BertSelfOutput y BertOutput: Estas subunidades procesan la salida del mecanismo de atención y luego la combinan con la entrada original de la capa (residual connection), seguido de normalización y dropout.\n",
    "        + BertIntermediate: Transforma la dimensión de la salida de la atención de 768 a 3072 y luego aplica una función de activación GELU.\n",
    "\n",
    "\n",
    "3. Dropout:\n",
    "Un dropout adicional para regularizar el modelo completo y evitar el sobreajuste (overfitting).\n",
    "\n",
    "\n",
    "4. Classifier:\n",
    "Una capa lineal que toma la salida de 768 dimensiones del último encoder de BERT y la proyecta a un espacio de 9 dimensiones, que corresponde al número de etiquetas de clasificación de tokens en este modelo específico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eef256c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TokenClassifierOutput(loss=None, logits=tensor([[[ 9.2208, -1.6785, -1.8515, -1.8754, -1.9307, -2.5917, -2.0250,\n",
       "          -0.1462, -0.1130],\n",
       "         [10.1709, -1.3370, -3.3993, -1.4356, -3.4063, -1.7803, -3.6719,\n",
       "           1.7097, -1.2047],\n",
       "         [10.6165, -2.7070, -1.9804, -3.0617, -1.8737, -3.8604, -2.2118,\n",
       "          -0.2796,  0.9794],\n",
       "         [10.6253, -2.1110, -2.3106, -3.0619, -1.8209, -3.8320, -1.9909,\n",
       "          -0.8844,  1.3295],\n",
       "         [ 2.2003,  5.1064, -2.7850, -0.9674, -4.6562,  0.5344, -4.4177,\n",
       "           3.5070, -1.1431],\n",
       "         [11.5247, -2.3492, -1.9350, -2.5357, -1.7421, -3.3117, -2.2463,\n",
       "          -0.9168, -0.6484],\n",
       "         [11.4987, -2.6115, -2.5543, -2.2295, -2.1211, -2.7356, -2.7921,\n",
       "          -0.1304, -0.5786],\n",
       "         [11.4484, -2.9085, -2.5226, -2.3606, -1.6497, -3.1620, -2.2045,\n",
       "          -0.9238,  0.0577],\n",
       "         [-0.4575, -3.0446, -2.7740, -0.0295, -0.6826,  9.4730, -1.5558,\n",
       "          -0.3724, -1.4893],\n",
       "         [11.5666, -2.7597, -2.2126, -2.3726, -1.6233, -3.2904, -2.0252,\n",
       "          -0.9551, -0.5454],\n",
       "         [11.5251, -2.8023, -2.7642, -2.1065, -1.9915, -2.7553, -2.6664,\n",
       "          -0.2423, -0.5266],\n",
       "         [11.3410, -3.1263, -2.8246, -1.9408, -1.5065, -3.3291, -2.2484,\n",
       "          -0.8314,  0.1605],\n",
       "         [ 2.0614, -1.4780, -4.7630,  5.5514, -2.1784,  2.0341, -3.7728,\n",
       "           2.5519, -1.2333],\n",
       "         [ 2.4714, -4.0864, -2.8393,  0.4386,  5.3038, -2.1188,  0.7347,\n",
       "          -1.1511,  0.9450],\n",
       "         [11.0944, -1.7515, -3.2960, -1.3437, -2.8130, -1.7162, -3.3753,\n",
       "           0.7352, -1.6880]]], grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo_ner(**vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d84ce93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = modelo_ner(**vector).logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "34d3f51a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 15, 9])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47c7b08",
   "metadata": {},
   "source": [
    "Las dimensiones del tensor que nos devuelve el modelo BERT son [1,15,9], una capa, 15 filas y 9 columns. La capa se refiere a la secuencia completa, 15 filas se corresponden con los 15 tokens de salida del tokenizador, incluidos los dos tokens especiales, y 9 columnas se refieren a las 9 etiquetas que maneja el modelo. Veamos otra vez cuales son:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "103b5200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'O',\n",
       " 1: 'B-PER',\n",
       " 2: 'I-PER',\n",
       " 3: 'B-ORG',\n",
       " 4: 'I-ORG',\n",
       " 5: 'B-LOC',\n",
       " 6: 'I-LOC',\n",
       " 7: 'B-MISC',\n",
       " 8: 'I-MISC'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etiquetas = modelo_ner.config.id2label\n",
    "\n",
    "etiquetas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c7bfbb",
   "metadata": {},
   "source": [
    "Ahora, para saber que etiqueta corresponde a cada token, debemos fijarnos en el argumento máximo en el tensor, puesto que para cada token tenemos 9 posibilidades. Calculemos los índices de los máximos de cada fila dentro del tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9743594d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 1, 0, 0, 0, 5, 0, 0, 0, 3, 4, 0]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = [int(e.argmax()) for e in tensor[0]]\n",
    "\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6b2ef43d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5733f8ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'O']\n"
     ]
    }
   ],
   "source": [
    "entidades = [etiquetas[e] for e in indices]\n",
    "\n",
    "print(entidades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1cb6fc5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'Mi', 'nombre', 'es', 'Juan', ',', 'vivo', 'en', 'Madrid', 'y', 'trabajo', 'en', 'BB', '##VA', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b262ae16",
   "metadata": {},
   "source": [
    "Para saber que entidad corresponde a cada token tan solo tenemos que juntarlos en un diccionario:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5f5c38d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'[CLS]': 'O',\n",
       " 'Mi': 'O',\n",
       " 'nombre': 'O',\n",
       " 'es': 'O',\n",
       " 'Juan': 'B-PER',\n",
       " ',': 'O',\n",
       " 'vivo': 'O',\n",
       " 'en': 'O',\n",
       " 'Madrid': 'B-LOC',\n",
       " 'y': 'O',\n",
       " 'trabajo': 'O',\n",
       " 'BB': 'B-ORG',\n",
       " '##VA': 'I-ORG',\n",
       " '[SEP]': 'O'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(zip(tokens, entidades))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62fa216",
   "metadata": {},
   "source": [
    "Este es el resultado final del modelo NER, cada token con su entidad. A partir de aquí, podríamos construir nuestra propia función para que nos devuelva la salida que necesitemos según la aplicación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5294a31f",
   "metadata": {},
   "source": [
    "## 4 - Combinando pipeline y modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2decb49e",
   "metadata": {},
   "source": [
    "Existe otra manera de usar los modelos de tranformers, combinando el pipeline con el tokenizador y modelo preentrenado. El resultado será el mismo que usando solamente el pipeline, pero puede ser que nos encontremos con esta estructura en el hub de Hugging Face. Veamos como se hace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fa81fd87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'PER',\n",
       "  'score': 0.78810596,\n",
       "  'word': 'Juan',\n",
       "  'start': 22,\n",
       "  'end': 26},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': 0.99981457,\n",
       "  'word': 'Madrid',\n",
       "  'start': 36,\n",
       "  'end': 42},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': 0.9998276,\n",
       "  'word': 'Barcelona',\n",
       "  'start': 73,\n",
       "  'end': 82},\n",
       " {'entity_group': 'PER',\n",
       "  'score': 0.94034415,\n",
       "  'word': 'Nerón',\n",
       "  'start': 110,\n",
       "  'end': 115},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': 0.9921303,\n",
       "  'word': 'BBVA',\n",
       "  'start': 136,\n",
       "  'end': 140},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': 0.9946945,\n",
       "  'word': 'Vodafone',\n",
       "  'start': 171,\n",
       "  'end': 179}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "\n",
    "\n",
    "tarea = 'ner'\n",
    "\n",
    "modelo = 'Babelscape/wikineural-multilingual-ner'\n",
    "\n",
    "\n",
    "tokenizador = AutoTokenizer.from_pretrained(modelo)\n",
    "modelo_ner = AutoModelForTokenClassification.from_pretrained(modelo)\n",
    "\n",
    "\n",
    "ner_pipe = pipeline(task=tarea, model=modelo_ner, tokenizer=tokenizador, aggregation_strategy='simple')\n",
    "\n",
    "\n",
    "\n",
    "frase = '''\n",
    "        Mi nombre es Juan, vivo en Madrid,\n",
    "        aunque a veces voy a Barcelona.\n",
    "        Mi perro se llama Nerón.\n",
    "        Trabajo en BBVA, pero mi ultimo puesto fue en Vodafone.\n",
    "        '''\n",
    "\n",
    "\n",
    "\n",
    "resultado = ner_pipe(frase)\n",
    "\n",
    "resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83aefba",
   "metadata": {},
   "source": [
    "## 5 - Visualización de entidades\n",
    "\n",
    "Visualizar las entidades en formato diccionario no resulta muy cómodo. Sería mucho mejor poder visualizar directamente las entidades en el texto. Para ello tenemos disponible la herramienta [ipymarkup](https://github.com/natasha/ipymarkup?tab=readme-ov-file), una librería que colores las entidades e incluso nos permite crear el HTML necesario para incrustarlo en una aplicación web. Lo primero será instalar la librería ejecutando ell siguiente código en la terminal:\n",
    "\n",
    "```bash\n",
    "pip install ipymarkup\n",
    "```\n",
    "\n",
    "Siguiendo la [documentación](https://nbviewer.org/github/natasha/ipymarkup/blob/master/docs.ipynb) de la librería, vemos que en realidad necesitamos una lista de tuplas con el siguiente formato: \n",
    "\n",
    "`[(start, end, entidad), (start, end, entidad), ...]`\n",
    "\n",
    "Cada tupla tiene 2 números enteros y una string con el nombre de la entidad. Necesitamos transformar la salida del pipeline a esta estructura para poder usar la librería. Además nos permite visualizarlo de varias maneras. Veamos cómo:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a9286187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(22, 26, 'PER'),\n",
       " (36, 42, 'LOC'),\n",
       " (73, 82, 'LOC'),\n",
       " (110, 115, 'PER'),\n",
       " (136, 140, 'ORG'),\n",
       " (171, 179, 'ORG')]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rangos_ents = [(e['start'], e['end'], e['entity_group']) for e in resultado]\n",
    "\n",
    "rangos_ents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c3f0e0",
   "metadata": {},
   "source": [
    "La función `show_span_ascii_markup` nos subraya las entidades con su nombre al pasarle la frase y los rangos de la entidades que acabamos de crear:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f1edc9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipymarkup import show_span_ascii_markup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "da3093a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Mi nombre es Juan, vivo en Madrid,\n",
      "                     PER─          LOC─── \n",
      "        aunque a veces voy a Barcelona.\n",
      "                             LOC────── \n",
      "        Mi perro se llama Nerón.\n",
      "                          PER── \n",
      "        Trabajo en BBVA, pero mi ultimo puesto fue en Vodafone.\n",
      "                   ORG─                               ORG───── \n",
      "        \n"
     ]
    }
   ],
   "source": [
    "show_span_ascii_markup(frase, rangos_ents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429d0f74",
   "metadata": {},
   "source": [
    "La función `show_span_line_markup` hace básicamente lo mismo que la anterior, pero formatea la fuente y colorea el subrayado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d4560543",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipymarkup import show_span_line_markup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "62bd58ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tex2jax_ignore\" style=\"white-space: pre-wrap\"><div><span style=\"display: inline-block; vertical-align: top\">        Mi nombre es </span><span style=\"display: inline-block; vertical-align: top; position: relative; margin-bottom: 11px\"><span style=\"border-bottom: 3px solid #90caf9; padding-bottom: 8px\">Juan</span><span style=\"font-size: 11px; line-height: 1; white-space: nowrap; text-shadow: 1px 1px 0px white; position: absolute; left: 0; bottom: -8px\">PER</span></span><span style=\"display: inline-block; vertical-align: top\">, vivo en </span><span style=\"display: inline-block; vertical-align: top; position: relative; margin-bottom: 11px\"><span style=\"border-bottom: 3px solid #a5d6a7; padding-bottom: 8px\">Madrid</span><span style=\"font-size: 11px; line-height: 1; white-space: nowrap; text-shadow: 1px 1px 0px white; position: absolute; left: 0; bottom: -8px\">LOC</span></span><span style=\"display: inline-block; vertical-align: top\">,</span></div><div><span style=\"display: inline-block; vertical-align: top\">        aunque a veces voy a </span><span style=\"display: inline-block; vertical-align: top; position: relative; margin-bottom: 11px\"><span style=\"border-bottom: 3px solid #a5d6a7; padding-bottom: 8px\">Barcelona</span><span style=\"font-size: 11px; line-height: 1; white-space: nowrap; text-shadow: 1px 1px 0px white; position: absolute; left: 0; bottom: -8px\">LOC</span></span><span style=\"display: inline-block; vertical-align: top\">.</span></div><div><span style=\"display: inline-block; vertical-align: top\">        Mi perro se llama </span><span style=\"display: inline-block; vertical-align: top; position: relative; margin-bottom: 11px\"><span style=\"border-bottom: 3px solid #90caf9; padding-bottom: 8px\">Nerón</span><span style=\"font-size: 11px; line-height: 1; white-space: nowrap; text-shadow: 1px 1px 0px white; position: absolute; left: 0; bottom: -8px\">PER</span></span><span style=\"display: inline-block; vertical-align: top\">.</span></div><div><span style=\"display: inline-block; vertical-align: top\">        Trabajo en </span><span style=\"display: inline-block; vertical-align: top; position: relative; margin-bottom: 11px\"><span style=\"border-bottom: 3px solid #ef9a9a; padding-bottom: 8px\">BBVA</span><span style=\"font-size: 11px; line-height: 1; white-space: nowrap; text-shadow: 1px 1px 0px white; position: absolute; left: 0; bottom: -8px\">ORG</span></span><span style=\"display: inline-block; vertical-align: top\">, pero mi ultimo puesto fue en </span><span style=\"display: inline-block; vertical-align: top; position: relative; margin-bottom: 11px\"><span style=\"border-bottom: 3px solid #ef9a9a; padding-bottom: 8px\">Vodafone</span><span style=\"font-size: 11px; line-height: 1; white-space: nowrap; text-shadow: 1px 1px 0px white; position: absolute; left: 0; bottom: -8px\">ORG</span></span><span style=\"display: inline-block; vertical-align: top\">.</span></div><div><span style=\"display: inline-block; vertical-align: top\">        </span></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_span_line_markup(frase, rangos_ents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e0bdf4",
   "metadata": {},
   "source": [
    "Podemos cambiar el color del subrayado con la paleta de colores que provee la propia librería:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "68100218",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipymarkup.palette import palette, BLUE, RED, GREEN, ORANGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9328a9fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tex2jax_ignore\" style=\"white-space: pre-wrap\"><div><span style=\"display: inline-block; vertical-align: top\">        Mi nombre es </span><span style=\"display: inline-block; vertical-align: top; position: relative; margin-bottom: 11px\"><span style=\"border-bottom: 3px solid #90caf9; padding-bottom: 8px\">Juan</span><span style=\"font-size: 11px; line-height: 1; white-space: nowrap; text-shadow: 1px 1px 0px white; position: absolute; left: 0; bottom: -8px\">PER</span></span><span style=\"display: inline-block; vertical-align: top\">, vivo en </span><span style=\"display: inline-block; vertical-align: top; position: relative; margin-bottom: 11px\"><span style=\"border-bottom: 3px solid #90caf9; padding-bottom: 8px\">Madrid</span><span style=\"font-size: 11px; line-height: 1; white-space: nowrap; text-shadow: 1px 1px 0px white; position: absolute; left: 0; bottom: -8px\">LOC</span></span><span style=\"display: inline-block; vertical-align: top\">,</span></div><div><span style=\"display: inline-block; vertical-align: top\">        aunque a veces voy a </span><span style=\"display: inline-block; vertical-align: top; position: relative; margin-bottom: 11px\"><span style=\"border-bottom: 3px solid #90caf9; padding-bottom: 8px\">Barcelona</span><span style=\"font-size: 11px; line-height: 1; white-space: nowrap; text-shadow: 1px 1px 0px white; position: absolute; left: 0; bottom: -8px\">LOC</span></span><span style=\"display: inline-block; vertical-align: top\">.</span></div><div><span style=\"display: inline-block; vertical-align: top\">        Mi perro se llama </span><span style=\"display: inline-block; vertical-align: top; position: relative; margin-bottom: 11px\"><span style=\"border-bottom: 3px solid #90caf9; padding-bottom: 8px\">Nerón</span><span style=\"font-size: 11px; line-height: 1; white-space: nowrap; text-shadow: 1px 1px 0px white; position: absolute; left: 0; bottom: -8px\">PER</span></span><span style=\"display: inline-block; vertical-align: top\">.</span></div><div><span style=\"display: inline-block; vertical-align: top\">        Trabajo en </span><span style=\"display: inline-block; vertical-align: top; position: relative; margin-bottom: 11px\"><span style=\"border-bottom: 3px solid #90caf9; padding-bottom: 8px\">BBVA</span><span style=\"font-size: 11px; line-height: 1; white-space: nowrap; text-shadow: 1px 1px 0px white; position: absolute; left: 0; bottom: -8px\">ORG</span></span><span style=\"display: inline-block; vertical-align: top\">, pero mi ultimo puesto fue en </span><span style=\"display: inline-block; vertical-align: top; position: relative; margin-bottom: 11px\"><span style=\"border-bottom: 3px solid #90caf9; padding-bottom: 8px\">Vodafone</span><span style=\"font-size: 11px; line-height: 1; white-space: nowrap; text-shadow: 1px 1px 0px white; position: absolute; left: 0; bottom: -8px\">ORG</span></span><span style=\"display: inline-block; vertical-align: top\">.</span></div><div><span style=\"display: inline-block; vertical-align: top\">        </span></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_span_line_markup(frase, rangos_ents, palette=palette(BLUE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982676c4",
   "metadata": {},
   "source": [
    "La función `show_span_box_markup` es un poco más amigable, dibuja una caja de color alrededor de la entidad y le pone la etiqueta dentro de la misma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "816e7537",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipymarkup import show_span_box_markup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "eaa88ef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tex2jax_ignore\" style=\"white-space: pre-wrap\">\n",
       "        Mi nombre es <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Juan<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span>, vivo en <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #c8e6c9; background: #e8f5e9\">Madrid<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #66bb6a;\">LOC</span></span>,\n",
       "        aunque a veces voy a <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #c8e6c9; background: #e8f5e9\">Barcelona<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #66bb6a;\">LOC</span></span>.\n",
       "        Mi perro se llama <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Nerón<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span>.\n",
       "        Trabajo en <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #ffcdd2; background: #ffebee\">BBVA<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #e57373;\">ORG</span></span>, pero mi ultimo puesto fue en <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #ffcdd2; background: #ffebee\">Vodafone<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #e57373;\">ORG</span></span>.\n",
       "        </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_span_box_markup(frase, rangos_ents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bc1eba",
   "metadata": {},
   "source": [
    "También podemos cambiar los colores de cada entidad con la paleta como hemos hecho antes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8417938c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tex2jax_ignore\" style=\"white-space: pre-wrap\">\n",
       "        Mi nombre es <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #ffe0b2; background: #fff3e0\">Juan<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #ffb74d;\">PER</span></span>, vivo en <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #ffcdd2; background: #ffebee\">Madrid<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #e57373;\">LOC</span></span>,\n",
       "        aunque a veces voy a <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #ffcdd2; background: #ffebee\">Barcelona<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #e57373;\">LOC</span></span>.\n",
       "        Mi perro se llama <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #ffe0b2; background: #fff3e0\">Nerón<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #ffb74d;\">PER</span></span>.\n",
       "        Trabajo en <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">BBVA<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">ORG</span></span>, pero mi ultimo puesto fue en <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Vodafone<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">ORG</span></span>.\n",
       "        </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_span_box_markup(frase, rangos_ents, palette=palette(PER=ORANGE, ORG=BLUE, LOC=RED))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877c64fc",
   "metadata": {},
   "source": [
    "Cabe mencionar que estas funciones solo nos muestran en el notebook el texto formateado. Pero no guardan la información del formateo. Probémoslo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "973e2f1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tex2jax_ignore\" style=\"white-space: pre-wrap\">\n",
       "        Mi nombre es <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #ffe0b2; background: #fff3e0\">Juan<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #ffb74d;\">PER</span></span>, vivo en <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #ffcdd2; background: #ffebee\">Madrid<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #e57373;\">LOC</span></span>,\n",
       "        aunque a veces voy a <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #ffcdd2; background: #ffebee\">Barcelona<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #e57373;\">LOC</span></span>.\n",
       "        Mi perro se llama <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #ffe0b2; background: #fff3e0\">Nerón<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #ffb74d;\">PER</span></span>.\n",
       "        Trabajo en <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">BBVA<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">ORG</span></span>, pero mi ultimo puesto fue en <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Vodafone<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">ORG</span></span>.\n",
       "        </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "texto = show_span_box_markup(frase, rangos_ents, palette=palette(PER=ORANGE, ORG=BLUE, LOC=RED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "54801a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(texto)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70903c1",
   "metadata": {},
   "source": [
    "Como vemos la variable que hemos creado no tiene valor, así que no hemos guardado el texto formateado como queríamos. Para hacerlo, ipymarkup nos proporciona otra función, `format_span_box_markup`, la cual nos permite guardar el texto coloreado directamente en formato HTML para ser incrustado en cualquier aplicación web:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ccb3e18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipymarkup import format_span_box_markup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9527daae",
   "metadata": {},
   "outputs": [],
   "source": [
    "html = list(format_span_box_markup(frase, rangos_ents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "07fbbd35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<div class=\"tex2jax_ignore\" style=\"white-space: pre-wrap\">', '\\n        Mi nombre es ', '<span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">', 'Juan', '<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">', 'PER', '</span>', '</span>', ', vivo en ', '<span style=\"padding: 2px; border-radius: 4px; border: 1px solid #c8e6c9; background: #e8f5e9\">', 'Madrid', '<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #66bb6a;\">', 'LOC', '</span>', '</span>', ',\\n        aunque a veces voy a ', '<span style=\"padding: 2px; border-radius: 4px; border: 1px solid #c8e6c9; background: #e8f5e9\">', 'Barcelona', '<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #66bb6a;\">', 'LOC', '</span>', '</span>', '.\\n        Mi perro se llama ', '<span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">', 'Nerón', '<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">', 'PER', '</span>', '</span>', '.\\n        Trabajo en ', '<span style=\"padding: 2px; border-radius: 4px; border: 1px solid #ffcdd2; background: #ffebee\">', 'BBVA', '<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #e57373;\">', 'ORG', '</span>', '</span>', ', pero mi ultimo puesto fue en ', '<span style=\"padding: 2px; border-radius: 4px; border: 1px solid #ffcdd2; background: #ffebee\">', 'Vodafone', '<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #e57373;\">', 'ORG', '</span>', '</span>', '.\\n        ', '</div>']\n"
     ]
    }
   ],
   "source": [
    "print(html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdc42b3",
   "metadata": {},
   "source": [
    "## 6 - Más modelos NER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c324ab58",
   "metadata": {},
   "source": [
    "Existen más modelos de NER en el hub de Hugging Face. Algunos de ellos están especializados en diversos temas. Por ejemplo, el modelo `Clinical-AI-Apollo/Medical-NER`, aquí el [link](https://huggingface.co/Clinical-AI-Apollo/Medical-NER), es un modelo especializado en temática médica. Es una versión de DeBERTa entrenado con el dataset [PubMED](https://huggingface.co/datasets/pubmed). El modelo pesa unos 750Mb y puede reconocer 41 entidades médicas.\n",
    "\n",
    "Vamos a cargar el modelo y le daremos el texto de una carta de un paciente a su doctor por síntomas gripales, escrita en inglés, puesto que normalmente estos modelos funcionan mejor en esa lengua. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "79ca31ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "tarea = 'ner'\n",
    "\n",
    "modelo = 'Clinical-AI-Apollo/Medical-NER'\n",
    "\n",
    "tokenizador = AutoTokenizer.from_pretrained(modelo)\n",
    "modelo_ner = AutoModelForTokenClassification.from_pretrained(modelo)\n",
    "\n",
    "\n",
    "ner_pipe = pipeline(task=tarea, model=modelo_ner, tokenizer=tokenizador, aggregation_strategy='simple')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "80d70432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'O', 1: 'B-ACTIVITY', 2: 'I-ACTIVITY', 3: 'I-ADMINISTRATION', 4: 'B-ADMINISTRATION', 5: 'B-AGE', 6: 'I-AGE', 7: 'I-AREA', 8: 'B-AREA', 9: 'B-BIOLOGICAL_ATTRIBUTE', 10: 'I-BIOLOGICAL_ATTRIBUTE', 11: 'I-BIOLOGICAL_STRUCTURE', 12: 'B-BIOLOGICAL_STRUCTURE', 13: 'B-CLINICAL_EVENT', 14: 'I-CLINICAL_EVENT', 15: 'B-COLOR', 16: 'I-COLOR', 17: 'I-COREFERENCE', 18: 'B-COREFERENCE', 19: 'B-DATE', 20: 'I-DATE', 21: 'I-DETAILED_DESCRIPTION', 22: 'B-DETAILED_DESCRIPTION', 23: 'I-DIAGNOSTIC_PROCEDURE', 24: 'B-DIAGNOSTIC_PROCEDURE', 25: 'I-DISEASE_DISORDER', 26: 'B-DISEASE_DISORDER', 27: 'B-DISTANCE', 28: 'I-DISTANCE', 29: 'B-DOSAGE', 30: 'I-DOSAGE', 31: 'I-DURATION', 32: 'B-DURATION', 33: 'I-FAMILY_HISTORY', 34: 'B-FAMILY_HISTORY', 35: 'B-FREQUENCY', 36: 'I-FREQUENCY', 37: 'I-HEIGHT', 38: 'B-HEIGHT', 39: 'B-HISTORY', 40: 'I-HISTORY', 41: 'I-LAB_VALUE', 42: 'B-LAB_VALUE', 43: 'I-MASS', 44: 'B-MASS', 45: 'I-MEDICATION', 46: 'B-MEDICATION', 47: 'I-NONBIOLOGICAL_LOCATION', 48: 'B-NONBIOLOGICAL_LOCATION', 49: 'I-OCCUPATION', 50: 'B-OCCUPATION', 51: 'B-OTHER_ENTITY', 52: 'I-OTHER_ENTITY', 53: 'B-OTHER_EVENT', 54: 'I-OTHER_EVENT', 55: 'I-OUTCOME', 56: 'B-OUTCOME', 57: 'I-PERSONAL_BACKGROUND', 58: 'B-PERSONAL_BACKGROUND', 59: 'B-QUALITATIVE_CONCEPT', 60: 'I-QUALITATIVE_CONCEPT', 61: 'I-QUANTITATIVE_CONCEPT', 62: 'B-QUANTITATIVE_CONCEPT', 63: 'B-SEVERITY', 64: 'I-SEVERITY', 65: 'B-SEX', 66: 'I-SEX', 67: 'B-SHAPE', 68: 'I-SHAPE', 69: 'B-SIGN_SYMPTOM', 70: 'I-SIGN_SYMPTOM', 71: 'B-SUBJECT', 72: 'I-SUBJECT', 73: 'B-TEXTURE', 74: 'I-TEXTURE', 75: 'B-THERAPEUTIC_PROCEDURE', 76: 'I-THERAPEUTIC_PROCEDURE', 77: 'I-TIME', 78: 'B-TIME', 79: 'B-VOLUME', 80: 'I-VOLUME', 81: 'I-WEIGHT', 82: 'B-WEIGHT'}\n"
     ]
    }
   ],
   "source": [
    "print(modelo_ner.config.id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c3053f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# carta al doctor\n",
    "\n",
    "texto = '''\n",
    "\n",
    "Dear Doctor,\n",
    "\n",
    "I am writing to inform you of my current health condition and the symptoms I have been experiencing, \n",
    "which I suspect may be due to the flu. I have been feeling unwell for the past few days and thought \n",
    "it prudent to document my symptoms and treatment actions for your review.\n",
    "I am worried because I am 67 years old.\n",
    "\n",
    "Symptoms:\n",
    "\n",
    "High fever reaching up to 102°F (38.9°C), most noticeable in the evenings.\n",
    "Severe muscle aches and chills, which have been persistent.\n",
    "Congestion and a continuous cough, which has made it difficult to breathe easily.\n",
    "Fatigue, making it hard to get out of bed or engage in usual activities.\n",
    "Hospital:\n",
    "I have been in contact with the healthcare providers at [Hospital Name], where I received initial screening. \n",
    "They advised me to monitor my symptoms closely and maintain fluid intake.\n",
    "\n",
    "Pain Frequency:\n",
    "The muscle aches and headaches are nearly constant throughout the day, with pain intensifying during the night, \n",
    "affecting my ability to sleep.\n",
    "\n",
    "Medication:\n",
    "I am currently taking the following medications as per the over-the-counter recommendations and previous prescriptions:\n",
    "\n",
    "Ibuprofen 400 mg, every four to six hours as needed for fever and pain.\n",
    "Theraflu, to manage the symptoms of congestion and cough, taken every six hours.\n",
    "Ample fluids and rest have been recommended to facilitate recovery.\n",
    "I am keeping a close watch on my symptoms and will seek further medical assistance should my condition \n",
    "worsen or not improve within the next 48 hours. Please advise if there are any additional measures I should consider or if a follow-up appointment is necessary.\n",
    "\n",
    "Thank you for your attention to this matter. I look forward to your guidance and hope to recover swiftly \n",
    "with the appropriate care.\n",
    "\n",
    "Warm regards.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "db477cdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tex2jax_ignore\" style=\"white-space: pre-wrap\">\n",
       "\n",
       "Dear Doctor,\n",
       "\n",
       "I am writing to inform you of my current health condition and the symptoms I have been experiencing, \n",
       "which I suspect may be due to the<span style=\"padding: 2px; border-radius: 4px; border: 1px solid #ffe0b2; background: #fff3e0\"> flu<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #ffb74d;\">DISEASE_DISORDER</span></span>. I have been<span style=\"padding: 2px; border-radius: 4px; border: 1px solid #d1c4e9; background: #ede7f6\"> feeling<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #9575cd;\">SIGN_SYMPTOM</span></span><span style=\"padding: 2px; border-radius: 4px; border: 1px solid #d1c4e9; background: #ede7f6\"> unwell<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #9575cd;\">SIGN_SYMPTOM</span></span> for the<span style=\"padding: 2px; border-radius: 4px; border: 1px solid #d7ccc8; background: #efebe9\"> past few days<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #a1887f;\">DURATION</span></span> and thought \n",
       "it prudent to document my symptoms and treatment actions for your review.\n",
       "I am worried because I am<span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\"> 67 years old<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">AGE</span></span>.\n",
       "\n",
       "Symptoms:\n",
       "<span style=\"padding: 2px; border-radius: 4px; border: 1px solid #c8e6c9; background: #e8f5e9\">\n",
       "High<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #66bb6a;\">SEVERITY</span></span><span style=\"padding: 2px; border-radius: 4px; border: 1px solid #d1c4e9; background: #ede7f6\"> fever<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #9575cd;\">SIGN_SYMPTOM</span></span> reaching up to<span style=\"padding: 2px; border-radius: 4px; border: 1px solid #ffcdd2; background: #ffebee\"> 102°F<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #e57373;\">LAB_VALUE</span></span> (38<span style=\"padding: 2px; border-radius: 4px; border: 1px solid #ffcdd2; background: #ffebee\">.<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #e57373;\">LAB_VALUE</span></span>9°C), most noticeable in<span style=\"padding: 2px; border-radius: 4px; border: 1px solid #ffe0b2; background: #fff3e0\"> the evenings<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #ffb74d;\">DETAILED_DESCRIPTION</span></span>.<span style=\"padding: 2px; border-radius: 4px; border: 1px solid #c8e6c9; background: #e8f5e9\">\n",
       "Severe<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #66bb6a;\">SEVERITY</span></span><span style=\"padding: 2px; border-radius: 4px; border: 1px solid #d1c4e9; background: #ede7f6\"> muscle<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #9575cd;\">BIOLOGICAL_STRUCTURE</span></span><span style=\"padding: 2px; border-radius: 4px; border: 1px solid #d1c4e9; background: #ede7f6\"> aches<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #9575cd;\">SIGN_SYMPTOM</span></span> and<span style=\"padding: 2px; border-radius: 4px; border: 1px solid #d1c4e9; background: #ede7f6\"> chills<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #9575cd;\">SIGN_SYMPTOM</span></span>, which have been persistent.<span style=\"padding: 2px; border-radius: 4px; border: 1px solid #d1c4e9; background: #ede7f6\">\n",
       "Congestion<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #9575cd;\">SIGN_SYMPTOM</span></span> and a<span style=\"padding: 2px; border-radius: 4px; border: 1px solid #ffe0b2; background: #fff3e0\"> continuous<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #ffb74d;\">DETAILED_DESCRIPTION</span></span><span style=\"padding: 2px; border-radius: 4px; border: 1px solid #d1c4e9; background: #ede7f6\"> cough<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #9575cd;\">SIGN_SYMPTOM</span></span>, which has made it difficult to breathe easily.<span style=\"padding: 2px; border-radius: 4px; border: 1px solid #d1c4e9; background: #ede7f6\">\n",
       "Fatigue<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #9575cd;\">SIGN_SYMPTOM</span></span>, making it hard to get out of bed or engage in usual activities.<span style=\"padding: 2px; border-radius: 4px; border: 1px solid #d7ccc8; background: #efebe9\">\n",
       "Hospital<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #a1887f;\">NONBIOLOGICAL_LOCATION</span></span>:\n",
       "I have been in contact with the<span style=\"padding: 2px; border-radius: 4px; border: 1px solid #d7ccc8; background: #efebe9\"> healthcare providers<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #a1887f;\">NONBIOLOGICAL_LOCATION</span></span> at [Hospital Name], where I received initial screening. \n",
       "They advised me to monitor my symptoms closely and maintain<span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\"> fluid<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">THERAPEUTIC_PROCEDURE</span></span> intake.\n",
       "<span style=\"padding: 2px; border-radius: 4px; border: 1px solid #d1c4e9; background: #ede7f6\">\n",
       "Pain<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #9575cd;\">SIGN_SYMPTOM</span></span> Frequency:\n",
       "The<span style=\"padding: 2px; border-radius: 4px; border: 1px solid #d1c4e9; background: #ede7f6\"> muscle<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #9575cd;\">BIOLOGICAL_STRUCTURE</span></span><span style=\"padding: 2px; border-radius: 4px; border: 1px solid #d1c4e9; background: #ede7f6\"> aches<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #9575cd;\">SIGN_SYMPTOM</span></span> and<span style=\"padding: 2px; border-radius: 4px; border: 1px solid #d1c4e9; background: #ede7f6\"> headaches<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #9575cd;\">SIGN_SYMPTOM</span></span> are nearly constant throughout<span style=\"padding: 2px; border-radius: 4px; border: 1px solid #ffe0b2; background: #fff3e0\"> the day<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #ffb74d;\">DETAILED_DESCRIPTION</span></span>, with<span style=\"padding: 2px; border-radius: 4px; border: 1px solid #d1c4e9; background: #ede7f6\"> pain<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #9575cd;\">SIGN_SYMPTOM</span></span> intensifying during<span style=\"padding: 2px; border-radius: 4px; border: 1px solid #ffe0b2; background: #fff3e0\"> the night<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #ffb74d;\">DETAILED_DESCRIPTION</span></span>, \n",
       "affecting my ability to sleep.\n",
       "\n",
       "Medication:\n",
       "I am currently taking the following medications as per the over-the-counter recommendations and previous prescriptions:\n",
       "<span style=\"padding: 2px; border-radius: 4px; border: 1px solid #c8e6c9; background: #e8f5e9\">\n",
       "Ibuprofen<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #66bb6a;\">MEDICATION</span></span><span style=\"padding: 2px; border-radius: 4px; border: 1px solid #ffcdd2; background: #ffebee\"> 400 mg<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #e57373;\">DOSAGE</span></span>,<span style=\"padding: 2px; border-radius: 4px; border: 1px solid #ffcdd2; background: #ffebee\"> every four to six hours<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #e57373;\">DOSAGE</span></span> as needed for fever and pain.<span style=\"padding: 2px; border-radius: 4px; border: 1px solid #c8e6c9; background: #e8f5e9\">\n",
       "Theraflu<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #66bb6a;\">MEDICATION</span></span>, to manage the symptoms of<span style=\"padding: 2px; border-radius: 4px; border: 1px solid #d1c4e9; background: #ede7f6\"> congestion<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #9575cd;\">SIGN_SYMPTOM</span></span> and<span style=\"padding: 2px; border-radius: 4px; border: 1px solid #d1c4e9; background: #ede7f6\"> cough<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #9575cd;\">SIGN_SYMPTOM</span></span>, taken<span style=\"padding: 2px; border-radius: 4px; border: 1px solid #ffcdd2; background: #ffebee\"> every six hours<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #e57373;\">DOSAGE</span></span>.\n",
       "Ample<span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\"> fluids<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">THERAPEUTIC_PROCEDURE</span></span> and<span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\"> rest<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">THERAPEUTIC_PROCEDURE</span></span> have been recommended to facilitate recovery.\n",
       "I am keeping a close watch on my symptoms and will seek further medical assistance should my condition \n",
       "worsen or not improve within the<span style=\"padding: 2px; border-radius: 4px; border: 1px solid #d7ccc8; background: #efebe9\"> next 48 hours<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #a1887f;\">DURATION</span></span>. Please advise if there are any additional measures I should consider or if a follow-up appointment is necessary.\n",
       "\n",
       "Thank you for your attention to this matter. I look forward to your guidance and hope to recover swiftly \n",
       "with the appropriate care.\n",
       "\n",
       "Warm regards.\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resultado = ner_pipe(texto)\n",
    "\n",
    "rangos_ents = [(e['start'], e['end'], e['entity_group']) for e in resultado]\n",
    "\n",
    "show_span_box_markup(texto, rangos_ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d5d935",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ia",
   "language": "python",
   "name": "ia"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Tabla de Contenidos",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "599px",
    "left": "84px",
    "top": "111.141px",
    "width": "267.274px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
